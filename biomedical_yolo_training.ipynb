{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üè• YOLO Biomedical Object Detection - Complete Training Pipeline\n",
        "\n",
        "This notebook provides a complete walkthrough for training YOLO models on biomedical data with CSV annotations.\n",
        "\n",
        "## üìã What this notebook covers:\n",
        "1. **Data Loading & Exploration** - Load and visualize your CSV-annotated images\n",
        "2. **Data Preparation** - Convert CSV annotations to YOLO format\n",
        "3. **Dataset Creation** - Create train/validation/test splits\n",
        "4. **Model Training** - Train YOLO v9+ model with custom data\n",
        "5. **Model Evaluation** - Evaluate performance and visualize results\n",
        "6. **Inference** - Run predictions on new images\n",
        "\n",
        "## üéØ Prerequisites:\n",
        "- Images in JPG/PNG format\n",
        "- CSV files with object locations (x, y, width, height, class)\n",
        "- Python environment with required packages\n",
        "\n",
        "Let's get started! üöÄ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Step 1: Install and Import Required Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.196-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (2.6.0)\n",
            "Requirement already satisfied: torchvision in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (0.15.0.dev20230125)\n",
            "Requirement already satisfied: opencv-python in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (4.10.0.84)\n",
            "Requirement already satisfied: pillow in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (9.4.0)\n",
            "Requirement already satisfied: numpy in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (3.6.3)\n",
            "Requirement already satisfied: seaborn in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (0.12.2)\n",
            "Requirement already satisfied: pandas in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (1.2.1)\n",
            "Requirement already satisfied: tqdm in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (4.66.5)\n",
            "Requirement already satisfied: pyyaml in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (6.0)\n",
            "Requirement already satisfied: psutil in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from ultralytics) (5.9.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from ultralytics) (1.10.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from ultralytics) (2.32.3)\n",
            "Collecting ultralytics-thop>=2.0.0\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Collecting polars\n",
            "  Downloading polars-1.33.0-cp39-abi3-macosx_11_0_arm64.whl (35.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from torch) (3.0)\n",
            "Requirement already satisfied: jinja2 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: filelock in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from torch) (3.12.3)\n",
            "Requirement already satisfied: fsspec in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from torch) (2024.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.2.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from matplotlib) (23.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from matplotlib) (4.38.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from jinja2->torch) (2.1.2)\n",
            "Installing collected packages: polars, ultralytics-thop, ultralytics\n",
            "Successfully installed polars-1.33.0 ultralytics-8.3.196 ultralytics-thop-2.0.17\n",
            "WARNING ‚ö†Ô∏è torchvision==0.15 is incompatible with torch==2.6.\n",
            "Run 'pip install torchvision==0.21' to fix torchvision or 'pip install -U torch torchvision' to update both.\n",
            "For a full compatibility table see https://github.com/pytorch/vision#installation\n",
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/Users/simpleai/Library/Application Support/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "‚úÖ All packages imported successfully!\n",
            "üîß PyTorch version: 2.6.0\n",
            "üîß CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "# Install required packages (run this cell first)\n",
        "!pip install ultralytics torch torchvision opencv-python pillow numpy matplotlib seaborn pandas scikit-learn tqdm pyyaml\n",
        "\n",
        "# Import all required libraries\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import json\n",
        "import yaml\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# YOLO imports\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ All packages imported successfully!\")\n",
        "print(f\"üîß PyTorch version: {torch.__version__}\")\n",
        "print(f\"üîß CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üîß GPU: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÅ Step 2: Data Loading and Exploration\n",
        "\n",
        "First, let's load and explore your CSV-annotated data. We'll create a data loader that can handle your specific CSV format and automatically convert grayscale images to RGB format (required by YOLO).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Loading data from: your_data\n",
            "üì∏ Found 0 images\n",
            "üìÑ Found 0 CSV files\n",
            "‚úÖ Loaded annotations for 0 images\n",
            "\n",
            "üìä Dataset Information:\n",
            "   Total images: 0\n",
            "   Total annotations: 0\n",
            "   Number of classes: 0\n",
            "   Average annotations per image: 0.00\n",
            "\n",
            "üìã Class distribution:\n",
            "\n",
            "üî¢ Class mapping:\n"
          ]
        }
      ],
      "source": [
        "# Simple data loading for 16-bit grayscale images with CSV annotations\n",
        "# Update this path to your data directory\n",
        "DATA_DIR = \"./your_data\"  # Change this to your actual data path\n",
        "\n",
        "print(f\"üîç Loading data from: {DATA_DIR}\")\n",
        "\n",
        "# Find all image files\n",
        "image_files = []\n",
        "for ext in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']:\n",
        "    image_files.extend(list(Path(DATA_DIR).glob(f\"*{ext}\")))\n",
        "    image_files.extend(list(Path(DATA_DIR).glob(f\"*{ext.upper()}\")))\n",
        "\n",
        "image_files = sorted(image_files)\n",
        "print(f\"üì∏ Found {len(image_files)} images\")\n",
        "\n",
        "# Find CSV files\n",
        "csv_files = list(Path(DATA_DIR).glob(\"*.csv\"))\n",
        "print(f\"üìÑ Found {len(csv_files)} CSV files\")\n",
        "\n",
        "# Load CSV annotations\n",
        "annotations = {}\n",
        "for csv_file in csv_files:\n",
        "    print(f\"üìä Loading {csv_file.name}\")\n",
        "    df = pd.read_csv(csv_file)\n",
        "    print(f\"   Columns: {list(df.columns)}\")\n",
        "    print(f\"   Shape: {df.shape}\")\n",
        "    \n",
        "    # Process each row (assuming each row is one annotation)\n",
        "    for _, row in df.iterrows():\n",
        "        # Get image filename (you may need to adjust this based on your CSV structure)\n",
        "        # If CSV has filename column, use it; otherwise use CSV filename\n",
        "        if 'filename' in df.columns:\n",
        "            img_name = row['filename']\n",
        "        else:\n",
        "            # Use CSV filename as image name (remove .csv extension)\n",
        "            img_name = csv_file.stem + '.png'  # Adjust extension as needed\n",
        "        \n",
        "        if img_name not in annotations:\n",
        "            annotations[img_name] = []\n",
        "        \n",
        "        # Add annotation (class is always 0 since you have only one class)\n",
        "        annotation = {\n",
        "            'class_id': 0,  # Single class\n",
        "            'x': float(row['x']),\n",
        "            'y': float(row['y']),\n",
        "            'w': float(row['w']),\n",
        "            'h': float(row['h'])\n",
        "        }\n",
        "        annotations[img_name].append(annotation)\n",
        "\n",
        "print(f\"‚úÖ Loaded annotations for {len(annotations)} images\")\n",
        "\n",
        "# Convert 16-bit grayscale images to RGB\n",
        "print(\"üîÑ Converting 16-bit grayscale images to RGB...\")\n",
        "for img_path in image_files:\n",
        "    img = cv2.imread(str(img_path), cv2.IMREAD_UNCHANGED)\n",
        "    if img is not None and len(img.shape) == 2:  # Grayscale\n",
        "        print(f\"   Converting {img_path.name}: shape={img.shape}, dtype={img.dtype}\")\n",
        "        # Convert 16-bit grayscale to RGB by stacking channels\n",
        "        rgb_img = np.stack([img, img, img], axis=2)\n",
        "        # Save as 8-bit RGB for YOLO\n",
        "        rgb_img_8bit = (rgb_img / 256).astype(np.uint8)  # Convert 16-bit to 8-bit\n",
        "        cv2.imwrite(str(img_path), rgb_img_8bit)\n",
        "        print(f\"   ‚úÖ Converted to RGB\")\n",
        "\n",
        "print(\"‚úÖ Image conversion completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Step 3: Data Visualization and Exploration\n",
        "\n",
        "Let's visualize some of your data to understand the annotations and ensure everything is loaded correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è No data loaded. Please check your DATA_DIR path and ensure you have images and CSV files.\n"
          ]
        }
      ],
      "source": [
        "def visualize_annotations(image_path, annotations, class_mapping, max_images=4):\n",
        "    \"\"\"\n",
        "    Visualize images with their annotations\n",
        "    \"\"\"\n",
        "    # Create a figure with subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    # Get a sample of images with annotations\n",
        "    annotated_images = [(img, anns) for img, anns in zip(images, [annotations.get(img.name, []) for img in images]) if anns]\n",
        "    \n",
        "    for i, (img_path, img_annotations) in enumerate(annotated_images[:max_images]):\n",
        "        if i >= len(axes):\n",
        "            break\n",
        "            \n",
        "        # Load image\n",
        "        image = cv2.imread(str(img_path))\n",
        "        if image is not None:\n",
        "            # Convert BGR to RGB for display\n",
        "            if len(image.shape) == 3:\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            else:\n",
        "                # Handle grayscale images\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "        \n",
        "        # Draw annotations\n",
        "        for ann in img_annotations:\n",
        "            x, y, w, h = ann['x'], ann['y'], ann['width'], ann['height']\n",
        "            class_name = ann['class_name']\n",
        "            \n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(image, (int(x), int(y)), (int(x + w), int(y + h)), (255, 0, 0), 2)\n",
        "            \n",
        "            # Draw class label\n",
        "            cv2.putText(image, class_name, (int(x), int(y - 10)), \n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
        "        \n",
        "        # Display image\n",
        "        axes[i].imshow(image)\n",
        "        axes[i].set_title(f\"{img_path.name}\\n{len(img_annotations)} objects\")\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    # Hide unused subplots\n",
        "    for i in range(len(annotated_images), len(axes)):\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_class_distribution(class_counts):\n",
        "    \"\"\"Plot the distribution of classes\"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    classes = list(class_counts.keys())\n",
        "    counts = list(class_counts.values())\n",
        "    \n",
        "    bars = plt.bar(classes, counts, color='skyblue', edgecolor='navy', alpha=0.7)\n",
        "    plt.title('Class Distribution in Dataset', fontsize=16, fontweight='bold')\n",
        "    plt.xlabel('Class Names', fontsize=12)\n",
        "    plt.ylabel('Number of Annotations', fontsize=12)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar, count in zip(bars, counts):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
        "                str(count), ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_annotation_statistics(dataset_info):\n",
        "    \"\"\"Plot various annotation statistics\"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "    \n",
        "    # 1. Class distribution\n",
        "    classes = list(dataset_info['class_counts'].keys())\n",
        "    counts = list(dataset_info['class_counts'].values())\n",
        "    axes[0].pie(counts, labels=classes, autopct='%1.1f%%', startangle=90)\n",
        "    axes[0].set_title('Class Distribution (Pie Chart)')\n",
        "    \n",
        "    # 2. Total statistics\n",
        "    stats = ['Total Images', 'Total Annotations', 'Number of Classes']\n",
        "    values = [dataset_info['total_images'], dataset_info['total_annotations'], dataset_info['num_classes']]\n",
        "    bars = axes[1].bar(stats, values, color=['lightcoral', 'lightgreen', 'lightblue'])\n",
        "    axes[1].set_title('Dataset Statistics')\n",
        "    axes[1].set_ylabel('Count')\n",
        "    \n",
        "    # Add value labels\n",
        "    for bar, value in zip(bars, values):\n",
        "        axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
        "                    str(value), ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    # 3. Average annotations per image\n",
        "    axes[2].bar(['Avg Annotations/Image'], [dataset_info['avg_annotations_per_image']], \n",
        "               color='orange', alpha=0.7)\n",
        "    axes[2].set_title('Average Annotations per Image')\n",
        "    axes[2].set_ylabel('Count')\n",
        "    axes[2].text(0, dataset_info['avg_annotations_per_image'] + 0.1, \n",
        "                f\"{dataset_info['avg_annotations_per_image']:.2f}\", \n",
        "                ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize the data\n",
        "if len(images) > 0 and len(annotations) > 0:\n",
        "    print(\"üìä Visualizing sample images with annotations...\")\n",
        "    visualize_annotations(images[0], annotations, class_mapping)\n",
        "    \n",
        "    print(\"\\nüìà Plotting class distribution...\")\n",
        "    plot_class_distribution(dataset_info['class_counts'])\n",
        "    \n",
        "    print(\"\\nüìä Plotting dataset statistics...\")\n",
        "    plot_annotation_statistics(dataset_info)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No data loaded. Please check your DATA_DIR path and ensure you have images and CSV files.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Step 4: Convert CSV Annotations to YOLO Format\n",
        "\n",
        "Now we'll convert your CSV annotations to YOLO format and create the proper directory structure for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è No data to convert. Please ensure your data is loaded correctly.\n"
          ]
        }
      ],
      "source": [
        "# Simple YOLO dataset creation\n",
        "print(\"üîÑ Creating YOLO dataset...\")\n",
        "\n",
        "# Create directory structure\n",
        "output_dir = Path(\"./yolo_dataset\")\n",
        "directories = ['images/train', 'images/val', 'images/test', 'labels/train', 'labels/val', 'labels/test']\n",
        "for directory in directories:\n",
        "    (output_dir / directory).mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"‚úÖ Created directory: {output_dir / directory}\")\n",
        "\n",
        "# Get images with annotations\n",
        "annotated_images = []\n",
        "for img_path in image_files:\n",
        "    img_name = img_path.name\n",
        "    if img_name in annotations:\n",
        "        annotated_images.append((img_path, annotations[img_name]))\n",
        "\n",
        "print(f\"üì∏ Processing {len(annotated_images)} annotated images...\")\n",
        "\n",
        "# Split data (70% train, 20% val, 10% test)\n",
        "train_data, temp_data = train_test_split(annotated_images, train_size=0.7, random_state=42)\n",
        "val_data, test_data = train_test_split(temp_data, train_size=0.67, random_state=42)  # 0.67 of 30% = 20%\n",
        "\n",
        "print(f\"üìä Data split:\")\n",
        "print(f\"   Train: {len(train_data)} images\")\n",
        "print(f\"   Validation: {len(val_data)} images\")\n",
        "print(f\"   Test: {len(test_data)} images\")\n",
        "\n",
        "# Process each split\n",
        "splits = {'train': train_data, 'val': val_data, 'test': test_data}\n",
        "\n",
        "for split_name, split_data in splits.items():\n",
        "    print(f\"\\nüîÑ Processing {split_name} split...\")\n",
        "    \n",
        "    for img_path, img_annotations in split_data:\n",
        "        # Copy image\n",
        "        img_dest = output_dir / f\"images/{split_name}\" / img_path.name\n",
        "        shutil.copy2(img_path, img_dest)\n",
        "        \n",
        "        # Convert annotations to YOLO format\n",
        "        img = cv2.imread(str(img_path))\n",
        "        img_height, img_width = img.shape[:2]\n",
        "        \n",
        "        yolo_annotations = []\n",
        "        for ann in img_annotations:\n",
        "            # Convert to YOLO format (normalized center coordinates)\n",
        "            center_x = (ann['x'] + ann['w'] / 2) / img_width\n",
        "            center_y = (ann['y'] + ann['h'] / 2) / img_height\n",
        "            width = ann['w'] / img_width\n",
        "            height = ann['h'] / img_height\n",
        "            \n",
        "            yolo_annotations.append([ann['class_id'], center_x, center_y, width, height])\n",
        "        \n",
        "        # Save YOLO labels\n",
        "        label_dest = output_dir / f\"labels/{split_name}\" / f\"{img_path.stem}.txt\"\n",
        "        with open(label_dest, 'w') as f:\n",
        "            for ann in yolo_annotations:\n",
        "                f.write(' '.join([str(x) for x in ann]) + '\\n')\n",
        "\n",
        "# Create dataset.yaml\n",
        "yaml_content = {\n",
        "    'path': str(output_dir.absolute()),\n",
        "    'train': 'images/train',\n",
        "    'val': 'images/val',\n",
        "    'test': 'images/test',\n",
        "    'nc': 1,  # Single class\n",
        "    'names': ['object']  # Single class name\n",
        "}\n",
        "\n",
        "yaml_path = output_dir / 'dataset.yaml'\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.dump(yaml_content, f, default_flow_style=False)\n",
        "\n",
        "print(f\"‚úÖ Created dataset.yaml: {yaml_path}\")\n",
        "print(\"‚úÖ YOLO dataset created successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Step 5: Model Training\n",
        "\n",
        "Now let's train the YOLO model on your converted dataset. We'll use YOLOv9 with biomedical-optimized settings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple YOLO training\n",
        "print(\"üöÄ Starting YOLO training...\")\n",
        "\n",
        "# Check if dataset exists\n",
        "dataset_yaml_path = \"./yolo_dataset/dataset.yaml\"\n",
        "if os.path.exists(dataset_yaml_path):\n",
        "    print(f\"‚úÖ Dataset found: {dataset_yaml_path}\")\n",
        "    \n",
        "    # Load YOLO model\n",
        "    model = YOLO(\"yolov9c.pt\")\n",
        "    print(\"‚úÖ Model loaded successfully\")\n",
        "    \n",
        "    # Start training\n",
        "    results = model.train(\n",
        "        data=dataset_yaml_path,\n",
        "        epochs=100,\n",
        "        imgsz=640,\n",
        "        batch=16,\n",
        "        device=0,  # Use GPU (change to 'cpu' if no GPU)\n",
        "        project='biomedical_yolo',\n",
        "        name='simple_training',\n",
        "        exist_ok=True,\n",
        "        pretrained=True,\n",
        "        verbose=True,\n",
        "        val=True,\n",
        "        plots=True,\n",
        "        save_period=10,\n",
        "        \n",
        "        # Simple augmentation settings for biomedical data\n",
        "        hsv_h=0.01,\n",
        "        hsv_s=0.3,\n",
        "        hsv_v=0.2,\n",
        "        degrees=0.0,\n",
        "        translate=0.1,\n",
        "        scale=0.3,\n",
        "        fliplr=0.3,\n",
        "        mosaic=0.8,\n",
        "        mixup=0.0\n",
        "    )\n",
        "    \n",
        "    print(\"‚úÖ Training completed successfully!\")\n",
        "    \n",
        "    # Save best model path\n",
        "    best_model_path = results.save_dir / \"weights\" / \"best.pt\"\n",
        "    print(f\"üíæ Best model saved at: {best_model_path}\")\n",
        "    \n",
        "    # Save model path to a file for easy access\n",
        "    with open(\"best_model_path.txt\", \"w\") as f:\n",
        "        f.write(str(best_model_path))\n",
        "    print(\"üìù Model path saved to 'best_model_path.txt'\")\n",
        "    \n",
        "else:\n",
        "    print(f\"‚ùå Dataset not found: {dataset_yaml_path}\")\n",
        "    print(\"Please ensure you have run the data conversion step first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Step 6: Model Inference and Testing\n",
        "\n",
        "Let's test our trained model on some sample images to see how it performs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class YOLOInference:\n",
        "    \"\"\"\n",
        "    YOLO model inference for testing and prediction\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model_path, conf_threshold=0.25, iou_threshold=0.45):\n",
        "        self.model_path = model_path\n",
        "        self.conf_threshold = conf_threshold\n",
        "        self.iou_threshold = iou_threshold\n",
        "        self.model = None\n",
        "        \n",
        "    def load_model(self):\n",
        "        \"\"\"Load the trained YOLO model\"\"\"\n",
        "        print(f\"üîç Loading model from: {self.model_path}\")\n",
        "        self.model = YOLO(self.model_path)\n",
        "        print(\"‚úÖ Model loaded successfully\")\n",
        "        \n",
        "        # Get model info\n",
        "        print(f\"üìä Model information:\")\n",
        "        print(f\"   Classes: {list(self.model.names.values())}\")\n",
        "        print(f\"   Confidence threshold: {self.conf_threshold}\")\n",
        "        print(f\"   IoU threshold: {self.iou_threshold}\")\n",
        "    \n",
        "    def predict_single_image(self, image_path, save_results=True, output_dir=\"./inference_results\"):\n",
        "        \"\"\"Run inference on a single image\"\"\"\n",
        "        if self.model is None:\n",
        "            self.load_model()\n",
        "        \n",
        "        print(f\"üîç Processing image: {image_path}\")\n",
        "        \n",
        "        # Run inference\n",
        "        results = self.model(\n",
        "            image_path,\n",
        "            conf=self.conf_threshold,\n",
        "            iou=self.iou_threshold,\n",
        "            verbose=False\n",
        "        )\n",
        "        \n",
        "        # Process results\n",
        "        processed_results = self._process_results(results[0], image_path)\n",
        "        \n",
        "        # Save results if requested\n",
        "        if save_results:\n",
        "            self._save_results(processed_results, image_path, output_dir)\n",
        "        \n",
        "        return processed_results\n",
        "    \n",
        "    def predict_batch(self, image_dir, save_results=True, output_dir=\"./inference_results\"):\n",
        "        \"\"\"Run inference on a batch of images\"\"\"\n",
        "        if self.model is None:\n",
        "            self.load_model()\n",
        "        \n",
        "        print(f\"üîç Processing batch from: {image_dir}\")\n",
        "        \n",
        "        # Get all image files\n",
        "        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']\n",
        "        image_files = []\n",
        "        \n",
        "        for ext in image_extensions:\n",
        "            image_files.extend(Path(image_dir).glob(f\"*{ext}\"))\n",
        "            image_files.extend(Path(image_dir).glob(f\"*{ext.upper()}\"))\n",
        "        \n",
        "        if not image_files:\n",
        "            print(f\"‚ùå No images found in {image_dir}\")\n",
        "            return []\n",
        "        \n",
        "        print(f\"üì∏ Found {len(image_files)} images\")\n",
        "        \n",
        "        # Process each image\n",
        "        all_results = []\n",
        "        for i, image_path in enumerate(image_files):\n",
        "            print(f\"üîÑ Processing {i+1}/{len(image_files)}: {image_path.name}\")\n",
        "            try:\n",
        "                result = self.predict_single_image(str(image_path), save_results, output_dir)\n",
        "                all_results.append(result)\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error processing {image_path.name}: {str(e)}\")\n",
        "                continue\n",
        "        \n",
        "        return all_results\n",
        "    \n",
        "    def _process_results(self, result, image_path):\n",
        "        \"\"\"Process YOLO results into a structured format\"\"\"\n",
        "        processed = {\n",
        "            'image_path': image_path,\n",
        "            'image_shape': result.orig_shape,\n",
        "            'detections': [],\n",
        "            'summary': {}\n",
        "        }\n",
        "        \n",
        "        # Process detections\n",
        "        if result.boxes is not None:\n",
        "            boxes = result.boxes.xyxy.cpu().numpy()\n",
        "            confidences = result.boxes.conf.cpu().numpy()\n",
        "            class_ids = result.boxes.cls.cpu().numpy().astype(int)\n",
        "            \n",
        "            for i in range(len(boxes)):\n",
        "                detection = {\n",
        "                    'bbox': boxes[i].tolist(),  # [x1, y1, x2, y2]\n",
        "                    'confidence': float(confidences[i]),\n",
        "                    'class_id': int(class_ids[i]),\n",
        "                    'class_name': self.model.names[int(class_ids[i])]\n",
        "                }\n",
        "                processed['detections'].append(detection)\n",
        "        \n",
        "        # Add summary statistics\n",
        "        processed['summary'] = {\n",
        "            'total_detections': len(processed['detections']),\n",
        "            'classes_detected': list(set([d['class_name'] for d in processed['detections']])),\n",
        "            'confidence_range': {\n",
        "                'min': min([d['confidence'] for d in processed['detections']]) if processed['detections'] else 0,\n",
        "                'max': max([d['confidence'] for d in processed['detections']]) if processed['detections'] else 0\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        return processed\n",
        "    \n",
        "    def _save_results(self, results, image_path, output_dir):\n",
        "        \"\"\"Save inference results\"\"\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        \n",
        "        # Save JSON results\n",
        "        base_name = Path(image_path).stem\n",
        "        json_path = os.path.join(output_dir, f\"{base_name}_results.json\")\n",
        "        \n",
        "        with open(json_path, 'w') as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "        \n",
        "        # Save annotated image\n",
        "        annotated_image = self._create_annotated_image(image_path, results)\n",
        "        image_output_path = os.path.join(output_dir, f\"{base_name}_annotated.jpg\")\n",
        "        annotated_image.save(image_output_path)\n",
        "        \n",
        "        print(f\"üíæ Results saved to: {output_dir}\")\n",
        "    \n",
        "    def _create_annotated_image(self, image_path, results):\n",
        "        \"\"\"Create annotated image with bounding boxes and labels\"\"\"\n",
        "        # Load image\n",
        "        image = Image.open(image_path)\n",
        "        draw = ImageDraw.Draw(image)\n",
        "        \n",
        "        # Try to load a font, fall back to default if not available\n",
        "        try:\n",
        "            font = ImageFont.truetype(\"arial.ttf\", 16)\n",
        "        except:\n",
        "            font = ImageFont.load_default()\n",
        "        \n",
        "        # Draw detections\n",
        "        for detection in results['detections']:\n",
        "            bbox = detection['bbox']\n",
        "            class_name = detection['class_name']\n",
        "            confidence = detection['confidence']\n",
        "            \n",
        "            # Draw bounding box\n",
        "            x1, y1, x2, y2 = bbox\n",
        "            draw.rectangle([x1, y1, x2, y2], outline='red', width=3)\n",
        "            \n",
        "            # Draw label\n",
        "            label = f\"{class_name}: {confidence:.2f}\"\n",
        "            label_bbox = draw.textbbox((0, 0), label, font=font)\n",
        "            label_width = label_bbox[2] - label_bbox[0]\n",
        "            label_height = label_bbox[3] - label_bbox[1]\n",
        "            \n",
        "            # Draw label background\n",
        "            draw.rectangle([x1, y1-label_height-5, x1+label_width+10, y1], fill='red')\n",
        "            \n",
        "            # Draw label text\n",
        "            draw.text((x1+5, y1-label_height-2), label, fill='white', font=font)\n",
        "        \n",
        "        return image\n",
        "\n",
        "def visualize_inference_results(results, max_images=4):\n",
        "    \"\"\"Visualize inference results\"\"\"\n",
        "    if not results:\n",
        "        print(\"No results to visualize\")\n",
        "        return\n",
        "    \n",
        "    # Get sample results\n",
        "    sample_results = results[:max_images]\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for i, result in enumerate(sample_results):\n",
        "        if i >= len(axes):\n",
        "            break\n",
        "        \n",
        "        # Load original image\n",
        "        image = cv2.imread(result['image_path'])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Draw detections\n",
        "        for detection in result['detections']:\n",
        "            bbox = detection['bbox']\n",
        "            class_name = detection['class_name']\n",
        "            confidence = detection['confidence']\n",
        "            \n",
        "            x1, y1, x2, y2 = [int(coord) for coord in bbox]\n",
        "            \n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "            \n",
        "            # Draw label\n",
        "            label = f\"{class_name}: {confidence:.2f}\"\n",
        "            cv2.putText(image, label, (x1, y1 - 10), \n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
        "        \n",
        "        # Display image\n",
        "        axes[i].imshow(image)\n",
        "        axes[i].set_title(f\"{Path(result['image_path']).name}\\n{result['summary']['total_detections']} detections\")\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    # Hide unused subplots\n",
        "    for i in range(len(sample_results), len(axes)):\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Test inference on trained model\n",
        "if os.path.exists(\"best_model_path.txt\"):\n",
        "    with open(\"best_model_path.txt\", \"r\") as f:\n",
        "        model_path = f.read().strip()\n",
        "    \n",
        "    if os.path.exists(model_path):\n",
        "        print(f\"‚úÖ Found trained model: {model_path}\")\n",
        "        \n",
        "        # Initialize inference\n",
        "        inference = YOLOInference(model_path, conf_threshold=0.25, iou_threshold=0.45)\n",
        "        \n",
        "        # Test on validation images\n",
        "        val_images_dir = \"./yolo_dataset/images/val\"\n",
        "        if os.path.exists(val_images_dir):\n",
        "            print(\"üîç Running inference on validation images...\")\n",
        "            results = inference.predict_batch(val_images_dir, save_results=True)\n",
        "            \n",
        "            if results:\n",
        "                print(f\"\\nüìä Inference Results Summary:\")\n",
        "                total_detections = sum(r['summary']['total_detections'] for r in results)\n",
        "                print(f\"   Processed {len(results)} images\")\n",
        "                print(f\"   Total detections: {total_detections}\")\n",
        "                print(f\"   Average detections per image: {total_detections/len(results):.2f}\")\n",
        "                \n",
        "                # Visualize results\n",
        "                print(\"\\nüìä Visualizing inference results...\")\n",
        "                visualize_inference_results(results)\n",
        "            else:\n",
        "                print(\"‚ùå No inference results generated\")\n",
        "        else:\n",
        "            print(f\"‚ùå Validation images directory not found: {val_images_dir}\")\n",
        "    else:\n",
        "        print(f\"‚ùå Model file not found: {model_path}\")\n",
        "else:\n",
        "    print(\"‚ùå No trained model found. Please run the training step first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Step 7: Model Evaluation and Performance Analysis\n",
        "\n",
        "Let's evaluate our trained model's performance on the test set and generate comprehensive metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class YOLOEvaluator:\n",
        "    \"\"\"\n",
        "    Comprehensive YOLO model evaluation\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model_path, dataset_path, conf_threshold=0.25, iou_threshold=0.45):\n",
        "        self.model_path = model_path\n",
        "        self.dataset_path = dataset_path\n",
        "        self.conf_threshold = conf_threshold\n",
        "        self.iou_threshold = iou_threshold\n",
        "        self.model = None\n",
        "        self.class_names = None\n",
        "        \n",
        "    def load_model_and_dataset(self):\n",
        "        \"\"\"Load model and dataset information\"\"\"\n",
        "        print(f\"üîç Loading model from: {self.model_path}\")\n",
        "        self.model = YOLO(self.model_path)\n",
        "        \n",
        "        # Load dataset info\n",
        "        with open(self.dataset_path, 'r') as f:\n",
        "            dataset_info = yaml.safe_load(f)\n",
        "        \n",
        "        self.class_names = dataset_info['names']\n",
        "        self.dataset_root = Path(dataset_info['path'])\n",
        "        \n",
        "        print(f\"‚úÖ Model and dataset loaded successfully\")\n",
        "        print(f\"üìã Classes: {self.class_names}\")\n",
        "    \n",
        "    def evaluate_model(self, output_dir=\"./evaluation_results\"):\n",
        "        \"\"\"Run comprehensive model evaluation\"\"\"\n",
        "        if self.model is None:\n",
        "            self.load_model_and_dataset()\n",
        "        \n",
        "        print(\"üöÄ Starting model evaluation...\")\n",
        "        \n",
        "        # Create output directory\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        \n",
        "        # Get test images\n",
        "        test_images_dir = self.dataset_root / \"images/test\"\n",
        "        test_labels_dir = self.dataset_root / \"labels/test\"\n",
        "        \n",
        "        if not test_images_dir.exists():\n",
        "            print(\"‚ùå Test images directory not found\")\n",
        "            return\n",
        "        \n",
        "        test_images = list(test_images_dir.glob(\"*.jpg\")) + list(test_images_dir.glob(\"*.png\"))\n",
        "        \n",
        "        if not test_images:\n",
        "            print(\"‚ùå No test images found\")\n",
        "            return\n",
        "        \n",
        "        print(f\"üì∏ Found {len(test_images)} test images\")\n",
        "        \n",
        "        # Run predictions and collect ground truth\n",
        "        all_predictions = []\n",
        "        all_ground_truth = []\n",
        "        \n",
        "        for i, img_path in enumerate(test_images):\n",
        "            print(f\"üîÑ Processing {i+1}/{len(test_images)}: {img_path.name}\")\n",
        "            \n",
        "            # Get ground truth\n",
        "            gt_path = test_labels_dir / f\"{img_path.stem}.txt\"\n",
        "            ground_truth = self._load_ground_truth(gt_path, img_path)\n",
        "            \n",
        "            # Run prediction\n",
        "            predictions = self._run_prediction(img_path)\n",
        "            \n",
        "            # Store results\n",
        "            all_predictions.append(predictions)\n",
        "            all_ground_truth.append(ground_truth)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        evaluation_results = self._calculate_metrics(all_predictions, all_ground_truth)\n",
        "        \n",
        "        # Generate reports\n",
        "        self._generate_reports(evaluation_results, output_dir)\n",
        "        \n",
        "        # Create visualizations\n",
        "        self._create_visualizations(evaluation_results, output_dir)\n",
        "        \n",
        "        print(f\"‚úÖ Evaluation completed! Results saved to: {output_dir}\")\n",
        "        return evaluation_results\n",
        "    \n",
        "    def _load_ground_truth(self, label_path, image_path):\n",
        "        \"\"\"Load ground truth annotations\"\"\"\n",
        "        ground_truth = []\n",
        "        \n",
        "        if not label_path.exists():\n",
        "            return ground_truth\n",
        "        \n",
        "        # Load image dimensions\n",
        "        img = cv2.imread(str(image_path))\n",
        "        img_height, img_width = img.shape[:2]\n",
        "        \n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:\n",
        "                    class_id = int(parts[0])\n",
        "                    center_x = float(parts[1])\n",
        "                    center_y = float(parts[2])\n",
        "                    width = float(parts[3])\n",
        "                    height = float(parts[4])\n",
        "                    \n",
        "                    # Convert to absolute coordinates\n",
        "                    x1 = (center_x - width/2) * img_width\n",
        "                    y1 = (center_y - height/2) * img_height\n",
        "                    x2 = (center_x + width/2) * img_width\n",
        "                    y2 = (center_y + height/2) * img_height\n",
        "                    \n",
        "                    ground_truth.append({\n",
        "                        'class_id': class_id,\n",
        "                        'bbox': [x1, y1, x2, y2],\n",
        "                        'class_name': self.class_names[class_id]\n",
        "                    })\n",
        "        \n",
        "        return ground_truth\n",
        "    \n",
        "    def _run_prediction(self, image_path):\n",
        "        \"\"\"Run model prediction on single image\"\"\"\n",
        "        results = self.model(\n",
        "            str(image_path),\n",
        "            conf=self.conf_threshold,\n",
        "            iou=self.iou_threshold,\n",
        "            verbose=False\n",
        "        )\n",
        "        \n",
        "        predictions = []\n",
        "        if results[0].boxes is not None:\n",
        "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
        "            confidences = results[0].boxes.conf.cpu().numpy()\n",
        "            class_ids = results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "            \n",
        "            for i in range(len(boxes)):\n",
        "                predictions.append({\n",
        "                    'class_id': int(class_ids[i]),\n",
        "                    'bbox': boxes[i].tolist(),\n",
        "                    'confidence': float(confidences[i]),\n",
        "                    'class_name': self.class_names[int(class_ids[i])]\n",
        "                })\n",
        "        \n",
        "        return predictions\n",
        "    \n",
        "    def _calculate_metrics(self, predictions, ground_truth):\n",
        "        \"\"\"Calculate evaluation metrics\"\"\"\n",
        "        print(\"üìä Calculating evaluation metrics...\")\n",
        "        \n",
        "        # Initialize metrics storage\n",
        "        class_metrics = {i: {'tp': 0, 'fp': 0, 'fn': 0} for i in range(len(self.class_names))}\n",
        "        \n",
        "        # Calculate IoU and assign predictions to ground truth\n",
        "        for pred_list, gt_list in zip(predictions, ground_truth):\n",
        "            # For each ground truth, find best matching prediction\n",
        "            for gt in gt_list:\n",
        "                best_iou = 0\n",
        "                best_pred_idx = -1\n",
        "                \n",
        "                for i, pred in enumerate(pred_list):\n",
        "                    if pred['class_id'] == gt['class_id']:\n",
        "                        iou = self._calculate_iou(gt['bbox'], pred['bbox'])\n",
        "                        if iou > best_iou and iou >= self.iou_threshold:\n",
        "                            best_iou = iou\n",
        "                            best_pred_idx = i\n",
        "                \n",
        "                if best_pred_idx >= 0:\n",
        "                    class_metrics[gt['class_id']]['tp'] += 1\n",
        "                    # Remove matched prediction\n",
        "                    pred_list.pop(best_pred_idx)\n",
        "                else:\n",
        "                    class_metrics[gt['class_id']]['fn'] += 1\n",
        "            \n",
        "            # Remaining predictions are false positives\n",
        "            for pred in pred_list:\n",
        "                class_metrics[pred['class_id']]['fp'] += 1\n",
        "        \n",
        "        # Calculate per-class metrics\n",
        "        evaluation_results = {}\n",
        "        for class_id in range(len(self.class_names)):\n",
        "            tp = class_metrics[class_id]['tp']\n",
        "            fp = class_metrics[class_id]['fp']\n",
        "            fn = class_metrics[class_id]['fn']\n",
        "            \n",
        "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "            \n",
        "            evaluation_results[self.class_names[class_id]] = {\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1_score': f1,\n",
        "                'true_positives': tp,\n",
        "                'false_positives': fp,\n",
        "                'false_negatives': fn\n",
        "            }\n",
        "        \n",
        "        # Calculate overall metrics\n",
        "        total_tp = sum(class_metrics[c]['tp'] for c in range(len(self.class_names)))\n",
        "        total_fp = sum(class_metrics[c]['fp'] for c in range(len(self.class_names)))\n",
        "        total_fn = sum(class_metrics[c]['fn'] for c in range(len(self.class_names)))\n",
        "        \n",
        "        overall_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
        "        overall_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
        "        overall_f1 = 2 * (overall_precision * overall_recall) / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0\n",
        "        \n",
        "        evaluation_results['overall'] = {\n",
        "            'precision': overall_precision,\n",
        "            'recall': overall_recall,\n",
        "            'f1_score': overall_f1,\n",
        "            'true_positives': total_tp,\n",
        "            'false_positives': total_fp,\n",
        "            'false_negatives': total_fn\n",
        "        }\n",
        "        \n",
        "        return evaluation_results\n",
        "    \n",
        "    def _calculate_iou(self, bbox1, bbox2):\n",
        "        \"\"\"Calculate Intersection over Union between two bounding boxes\"\"\"\n",
        "        x1_1, y1_1, x2_1, y2_1 = bbox1\n",
        "        x1_2, y1_2, x2_2, y2_2 = bbox2\n",
        "        \n",
        "        # Calculate intersection\n",
        "        x1_i = max(x1_1, x1_2)\n",
        "        y1_i = max(y1_1, y1_2)\n",
        "        x2_i = min(x2_1, x2_2)\n",
        "        y2_i = min(y2_1, y2_2)\n",
        "        \n",
        "        if x2_i <= x1_i or y2_i <= y1_i:\n",
        "            return 0.0\n",
        "        \n",
        "        intersection = (x2_i - x1_i) * (y2_i - y1_i)\n",
        "        \n",
        "        # Calculate union\n",
        "        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
        "        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
        "        union = area1 + area2 - intersection\n",
        "        \n",
        "        return intersection / union if union > 0 else 0.0\n",
        "    \n",
        "    def _generate_reports(self, evaluation_results, output_dir):\n",
        "        \"\"\"Generate evaluation reports\"\"\"\n",
        "        print(\"üìù Generating evaluation reports...\")\n",
        "        \n",
        "        # Save detailed results\n",
        "        results_file = os.path.join(output_dir, \"evaluation_results.json\")\n",
        "        with open(results_file, 'w') as f:\n",
        "            json.dump(evaluation_results, f, indent=2)\n",
        "        \n",
        "        # Create summary report\n",
        "        summary_file = os.path.join(output_dir, \"evaluation_summary.txt\")\n",
        "        with open(summary_file, 'w') as f:\n",
        "            f.write(\"YOLO Biomedical Object Detection - Evaluation Summary\\n\")\n",
        "            f.write(\"=\" * 60 + \"\\n\\n\")\n",
        "            \n",
        "            f.write(\"Overall Performance:\\n\")\n",
        "            overall = evaluation_results['overall']\n",
        "            f.write(f\"  Precision: {overall['precision']:.4f}\\n\")\n",
        "            f.write(f\"  Recall: {overall['recall']:.4f}\\n\")\n",
        "            f.write(f\"  F1-Score: {overall['f1_score']:.4f}\\n\")\n",
        "            f.write(f\"  True Positives: {overall['true_positives']}\\n\")\n",
        "            f.write(f\"  False Positives: {overall['false_positives']}\\n\")\n",
        "            f.write(f\"  False Negatives: {overall['false_negatives']}\\n\\n\")\n",
        "            \n",
        "            f.write(\"Per-Class Performance:\\n\")\n",
        "            for class_name, metrics in evaluation_results.items():\n",
        "                if class_name != 'overall':\n",
        "                    f.write(f\"  {class_name}:\\n\")\n",
        "                    f.write(f\"    Precision: {metrics['precision']:.4f}\\n\")\n",
        "                    f.write(f\"    Recall: {metrics['recall']:.4f}\\n\")\n",
        "                    f.write(f\"    F1-Score: {metrics['f1_score']:.4f}\\n\")\n",
        "                    f.write(f\"    TP: {metrics['true_positives']}, FP: {metrics['false_positives']}, FN: {metrics['false_negatives']}\\n\\n\")\n",
        "        \n",
        "        print(f\"üìÑ Reports saved to: {output_dir}\")\n",
        "    \n",
        "    def _create_visualizations(self, evaluation_results, output_dir):\n",
        "        \"\"\"Create evaluation visualizations\"\"\"\n",
        "        print(\"üìä Creating visualizations...\")\n",
        "        \n",
        "        # 1. Per-class performance comparison\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "        \n",
        "        class_names = [name for name in evaluation_results.keys() if name != 'overall']\n",
        "        precisions = [evaluation_results[name]['precision'] for name in class_names]\n",
        "        recalls = [evaluation_results[name]['recall'] for name in class_names]\n",
        "        f1_scores = [evaluation_results[name]['f1_score'] for name in class_names]\n",
        "        \n",
        "        # Precision\n",
        "        axes[0].bar(class_names, precisions, color='skyblue')\n",
        "        axes[0].set_title('Per-Class Precision')\n",
        "        axes[0].set_ylabel('Precision')\n",
        "        axes[0].tick_params(axis='x', rotation=45)\n",
        "        axes[0].set_ylim(0, 1)\n",
        "        \n",
        "        # Recall\n",
        "        axes[1].bar(class_names, recalls, color='lightcoral')\n",
        "        axes[1].set_title('Per-Class Recall')\n",
        "        axes[1].set_ylabel('Recall')\n",
        "        axes[1].tick_params(axis='x', rotation=45)\n",
        "        axes[1].set_ylim(0, 1)\n",
        "        \n",
        "        # F1-Score\n",
        "        axes[2].bar(class_names, f1_scores, color='lightgreen')\n",
        "        axes[2].set_title('Per-Class F1-Score')\n",
        "        axes[2].set_ylabel('F1-Score')\n",
        "        axes[2].tick_params(axis='x', rotation=45)\n",
        "        axes[2].set_ylim(0, 1)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_dir, \"per_class_performance.png\"), dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        # 2. Overall metrics pie chart\n",
        "        overall = evaluation_results['overall']\n",
        "        fig, ax = plt.subplots(figsize=(8, 8))\n",
        "        \n",
        "        labels = ['True Positives', 'False Positives', 'False Negatives']\n",
        "        sizes = [overall['true_positives'], overall['false_positives'], overall['false_negatives']]\n",
        "        colors = ['lightgreen', 'lightcoral', 'lightblue']\n",
        "        \n",
        "        ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
        "        ax.set_title('Overall Detection Results Distribution')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_dir, \"overall_distribution.png\"), dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        print(f\"üìä Visualizations saved to: {output_dir}\")\n",
        "\n",
        "# Run evaluation if model exists\n",
        "if os.path.exists(\"best_model_path.txt\"):\n",
        "    with open(\"best_model_path.txt\", \"r\") as f:\n",
        "        model_path = f.read().strip()\n",
        "    \n",
        "    dataset_yaml_path = \"./yolo_dataset/dataset.yaml\"\n",
        "    \n",
        "    if os.path.exists(model_path) and os.path.exists(dataset_yaml_path):\n",
        "        print(\"üìä Running comprehensive model evaluation...\")\n",
        "        \n",
        "        evaluator = YOLOEvaluator(\n",
        "            model_path=model_path,\n",
        "            dataset_path=dataset_yaml_path,\n",
        "            conf_threshold=0.25,\n",
        "            iou_threshold=0.45\n",
        "        )\n",
        "        \n",
        "        evaluation_results = evaluator.evaluate_model(\"./evaluation_results\")\n",
        "        \n",
        "        if evaluation_results:\n",
        "            print(\"\\nüìä Evaluation Summary:\")\n",
        "            overall = evaluation_results['overall']\n",
        "            print(f\"   Overall Precision: {overall['precision']:.4f}\")\n",
        "            print(f\"   Overall Recall: {overall['recall']:.4f}\")\n",
        "            print(f\"   Overall F1-Score: {overall['f1_score']:.4f}\")\n",
        "            print(f\"   Total Detections: {overall['true_positives'] + overall['false_positives']}\")\n",
        "            print(f\"   Total Ground Truth: {overall['true_positives'] + overall['false_negatives']}\")\n",
        "    else:\n",
        "        print(\"‚ùå Model or dataset not found. Please ensure training completed successfully.\")\n",
        "else:\n",
        "    print(\"‚ùå No trained model found. Please run the training step first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Step 8: Summary and Next Steps\n",
        "\n",
        "Congratulations! You've successfully completed the entire YOLO training pipeline for biomedical object detection. Here's a summary of what we accomplished:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary of the complete pipeline\n",
        "print(\"üéâ YOLO Biomedical Object Detection - Training Complete!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nüìã What we accomplished:\")\n",
        "print(\"‚úÖ 1. Data Loading - Loaded CSV-annotated biomedical images\")\n",
        "print(\"‚úÖ 2. Data Visualization - Explored and visualized your dataset\")\n",
        "print(\"‚úÖ 3. Data Conversion - Converted CSV annotations to YOLO format\")\n",
        "print(\"‚úÖ 4. Dataset Creation - Created train/validation/test splits\")\n",
        "print(\"‚úÖ 5. Model Training - Trained YOLOv9 with biomedical-optimized settings\")\n",
        "print(\"‚úÖ 6. Model Inference - Tested predictions on validation data\")\n",
        "print(\"‚úÖ 7. Model Evaluation - Comprehensive performance analysis\")\n",
        "\n",
        "print(\"\\nüìÅ Generated files and directories:\")\n",
        "print(\"üìÇ yolo_dataset/ - YOLO format dataset\")\n",
        "print(\"üìÇ biomedical_yolo/ - Training results and model weights\")\n",
        "print(\"üìÇ inference_results/ - Inference results and annotated images\")\n",
        "print(\"üìÇ evaluation_results/ - Performance metrics and visualizations\")\n",
        "print(\"üìÑ best_model_path.txt - Path to your trained model\")\n",
        "\n",
        "print(\"\\nüîß Key features of this pipeline:\")\n",
        "print(\"‚Ä¢ Automatic CSV format detection and conversion\")\n",
        "print(\"‚Ä¢ Automatic grayscale to RGB conversion for YOLO compatibility\")\n",
        "print(\"‚Ä¢ Proper handling of float32/float64 images with dynamic range preservation\")\n",
        "print(\"‚Ä¢ Biomedical-optimized data augmentation\")\n",
        "print(\"‚Ä¢ Comprehensive evaluation metrics\")\n",
        "print(\"‚Ä¢ Visual result analysis\")\n",
        "print(\"‚Ä¢ Easy-to-use inference interface\")\n",
        "\n",
        "print(\"\\nüöÄ Next steps you can take:\")\n",
        "print(\"1. üîÑ Retrain with different parameters:\")\n",
        "print(\"   - Adjust epochs, batch size, or learning rate\")\n",
        "print(\"   - Try different YOLO model sizes (yolov9n, yolov9s, yolov9m, yolov9l, yolov9x)\")\n",
        "print(\"   - Experiment with different augmentation settings\")\n",
        "\n",
        "print(\"\\n2. üìä Improve model performance:\")\n",
        "print(\"   - Add more training data\")\n",
        "print(\"   - Balance your dataset classes\")\n",
        "print(\"   - Fine-tune hyperparameters\")\n",
        "print(\"   - Use data augmentation techniques\")\n",
        "\n",
        "print(\"\\n3. üîç Deploy your model:\")\n",
        "print(\"   - Use the trained model for inference on new images\")\n",
        "print(\"   - Integrate into your biomedical analysis pipeline\")\n",
        "print(\"   - Export to different formats (ONNX, TensorRT)\")\n",
        "\n",
        "print(\"\\n4. üìà Monitor and iterate:\")\n",
        "print(\"   - Track performance on new data\")\n",
        "print(\"   - Retrain with additional data\")\n",
        "print(\"   - Compare different model architectures\")\n",
        "\n",
        "print(\"\\nüí° Tips for better results:\")\n",
        "print(\"‚Ä¢ Ensure your CSV annotations are accurate\")\n",
        "print(\"‚Ä¢ Use high-quality, diverse training images\")\n",
        "print(\"‚Ä¢ Consider class imbalance in your dataset\")\n",
        "print(\"‚Ä¢ Monitor training metrics to avoid overfitting\")\n",
        "print(\"‚Ä¢ Validate on representative test data\")\n",
        "\n",
        "print(\"\\nüéØ Your trained model is ready for biomedical object detection!\")\n",
        "print(\"Use the inference functions to predict on new images.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
