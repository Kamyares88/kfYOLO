{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üè• YOLO Biomedical Object Detection - Complete Training Pipeline\n",
        "\n",
        "This notebook provides a complete walkthrough for training YOLO models on biomedical data with CSV annotations.\n",
        "\n",
        "## üìã What this notebook covers:\n",
        "1. **Data Loading & Exploration** - Load and visualize your CSV-annotated images\n",
        "2. **Data Preparation** - Convert CSV annotations to YOLO format\n",
        "3. **Dataset Creation** - Create train/validation/test splits\n",
        "4. **Model Training** - Train YOLO v9+ model with custom data\n",
        "5. **Model Evaluation** - Evaluate performance and visualize results\n",
        "6. **Inference** - Run predictions on new images\n",
        "\n",
        "## üéØ Prerequisites:\n",
        "- Images in JPG/PNG format\n",
        "- CSV files with object locations (x, y, width, height, class)\n",
        "- Python environment with required packages\n",
        "\n",
        "Let's get started! üöÄ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Step 1: Install and Import Required Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.196-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (2.6.0)\n",
            "Requirement already satisfied: torchvision in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (0.15.0.dev20230125)\n",
            "Requirement already satisfied: opencv-python in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (4.10.0.84)\n",
            "Requirement already satisfied: pillow in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (9.4.0)\n",
            "Requirement already satisfied: numpy in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (3.6.3)\n",
            "Requirement already satisfied: seaborn in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (0.12.2)\n",
            "Requirement already satisfied: pandas in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (1.2.1)\n",
            "Requirement already satisfied: tqdm in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (4.66.5)\n",
            "Requirement already satisfied: pyyaml in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (6.0)\n",
            "Requirement already satisfied: psutil in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from ultralytics) (5.9.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from ultralytics) (1.10.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from ultralytics) (2.32.3)\n",
            "Collecting ultralytics-thop>=2.0.0\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Collecting polars\n",
            "  Downloading polars-1.33.0-cp39-abi3-macosx_11_0_arm64.whl (35.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from torch) (3.0)\n",
            "Requirement already satisfied: jinja2 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: filelock in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from torch) (3.12.3)\n",
            "Requirement already satisfied: fsspec in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from torch) (2024.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.2.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from matplotlib) (23.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from matplotlib) (4.38.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/simpleai/miniforge3/envs/torch-gpu2/lib/python3.9/site-packages (from jinja2->torch) (2.1.2)\n",
            "Installing collected packages: polars, ultralytics-thop, ultralytics\n",
            "Successfully installed polars-1.33.0 ultralytics-8.3.196 ultralytics-thop-2.0.17\n",
            "WARNING ‚ö†Ô∏è torchvision==0.15 is incompatible with torch==2.6.\n",
            "Run 'pip install torchvision==0.21' to fix torchvision or 'pip install -U torch torchvision' to update both.\n",
            "For a full compatibility table see https://github.com/pytorch/vision#installation\n",
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/Users/simpleai/Library/Application Support/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "‚úÖ All packages imported successfully!\n",
            "üîß PyTorch version: 2.6.0\n",
            "üîß CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "# Install required packages (run this cell first)\n",
        "!pip install ultralytics torch torchvision opencv-python pillow numpy matplotlib seaborn pandas scikit-learn tqdm pyyaml\n",
        "\n",
        "# Import all required libraries\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import json\n",
        "import yaml\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# YOLO imports\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ All packages imported successfully!\")\n",
        "print(f\"üîß PyTorch version: {torch.__version__}\")\n",
        "print(f\"üîß CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üîß GPU: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÅ Step 2: Data Loading and Exploration\n",
        "\n",
        "First, let's load and explore your CSV-annotated data. We'll create a data loader that can handle your specific CSV format.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Loading data from: your_data\n",
            "üì∏ Found 0 images\n",
            "üìÑ Found 0 CSV files\n",
            "‚úÖ Loaded annotations for 0 images\n",
            "\n",
            "üìä Dataset Information:\n",
            "   Total images: 0\n",
            "   Total annotations: 0\n",
            "   Number of classes: 0\n",
            "   Average annotations per image: 0.00\n",
            "\n",
            "üìã Class distribution:\n",
            "\n",
            "üî¢ Class mapping:\n"
          ]
        }
      ],
      "source": [
        "class CSVDataLoader:\n",
        "    \"\"\"\n",
        "    Data loader for CSV-annotated biomedical images\n",
        "    Supports various CSV formats commonly used in biomedical datasets\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, data_dir, image_extensions=['.jpg', '.jpeg', '.png', '.bmp', '.tiff']):\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.image_extensions = image_extensions\n",
        "        self.images = []\n",
        "        self.annotations = {}\n",
        "        self.class_mapping = {}\n",
        "        \n",
        "    def load_data(self):\n",
        "        \"\"\"Load all images and their corresponding CSV annotations\"\"\"\n",
        "        print(f\"üîç Loading data from: {self.data_dir}\")\n",
        "        \n",
        "        # Find all image files\n",
        "        for ext in self.image_extensions:\n",
        "            self.images.extend(list(self.data_dir.glob(f\"*{ext}\")))\n",
        "            self.images.extend(list(self.data_dir.glob(f\"*{ext.upper()}\")))\n",
        "        \n",
        "        self.images = sorted(self.images)\n",
        "        print(f\"üì∏ Found {len(self.images)} images\")\n",
        "        \n",
        "        # Load CSV annotations\n",
        "        csv_files = list(self.data_dir.glob(\"*.csv\"))\n",
        "        print(f\"üìÑ Found {len(csv_files)} CSV files\")\n",
        "        \n",
        "        for csv_file in csv_files:\n",
        "            self._load_csv_annotations(csv_file)\n",
        "        \n",
        "        print(f\"‚úÖ Loaded annotations for {len(self.annotations)} images\")\n",
        "        return self.images, self.annotations\n",
        "    \n",
        "    def _load_csv_annotations(self, csv_file):\n",
        "        \"\"\"Load annotations from a CSV file\"\"\"\n",
        "        try:\n",
        "            df = pd.read_csv(csv_file)\n",
        "            print(f\"üìä CSV columns: {list(df.columns)}\")\n",
        "            \n",
        "            # Try to detect the format automatically\n",
        "            format_type = self._detect_csv_format(df)\n",
        "            print(f\"üîç Detected format: {format_type}\")\n",
        "            \n",
        "            # Process annotations based on format\n",
        "            if format_type == 'filename_based':\n",
        "                self._process_filename_based_csv(df)\n",
        "            elif format_type == 'image_based':\n",
        "                self._process_image_based_csv(df)\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Unknown CSV format in {csv_file.name}\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading {csv_file.name}: {str(e)}\")\n",
        "    \n",
        "    def _detect_csv_format(self, df):\n",
        "        \"\"\"Detect the CSV annotation format\"\"\"\n",
        "        columns = [col.lower() for col in df.columns]\n",
        "        \n",
        "        # Check for filename-based format\n",
        "        if any('filename' in col or 'image' in col for col in columns):\n",
        "            return 'filename_based'\n",
        "        \n",
        "        # Check for image-based format (one row per image)\n",
        "        if any('x' in col and 'y' in col for col in columns):\n",
        "            return 'image_based'\n",
        "        \n",
        "        return 'unknown'\n",
        "    \n",
        "    def _process_filename_based_csv(self, df):\n",
        "        \"\"\"Process CSV where each row represents one annotation\"\"\"\n",
        "        # Common column name mappings\n",
        "        col_mapping = {\n",
        "            'filename': ['filename', 'image', 'image_name', 'file'],\n",
        "            'class': ['class', 'label', 'category', 'class_name'],\n",
        "            'x': ['x', 'x_min', 'xmin', 'left'],\n",
        "            'y': ['y', 'y_min', 'ymin', 'top'],\n",
        "            'width': ['width', 'w'],\n",
        "            'height': ['height', 'h']\n",
        "        }\n",
        "        \n",
        "        # Find actual column names\n",
        "        actual_cols = {}\n",
        "        for key, possible_names in col_mapping.items():\n",
        "            for col in df.columns:\n",
        "                if col.lower() in possible_names:\n",
        "                    actual_cols[key] = col\n",
        "                    break\n",
        "        \n",
        "        print(f\"üìã Column mapping: {actual_cols}\")\n",
        "        \n",
        "        # Group by filename\n",
        "        for filename, group in df.groupby(actual_cols['filename']):\n",
        "            annotations = []\n",
        "            for _, row in group.iterrows():\n",
        "                class_name = str(row[actual_cols['class']])\n",
        "                \n",
        "                # Create class mapping\n",
        "                if class_name not in self.class_mapping:\n",
        "                    self.class_mapping[class_name] = len(self.class_mapping)\n",
        "                \n",
        "                annotation = {\n",
        "                    'class_id': self.class_mapping[class_name],\n",
        "                    'class_name': class_name,\n",
        "                    'x': float(row[actual_cols['x']]),\n",
        "                    'y': float(row[actual_cols['y']]),\n",
        "                    'width': float(row[actual_cols['width']]),\n",
        "                    'height': float(row[actual_cols['height']])\n",
        "                }\n",
        "                annotations.append(annotation)\n",
        "            \n",
        "            self.annotations[filename] = annotations\n",
        "    \n",
        "    def _process_image_based_csv(self, df):\n",
        "        \"\"\"Process CSV where each row represents one image with multiple objects\"\"\"\n",
        "        # This format is less common but we'll handle it\n",
        "        print(\"‚ö†Ô∏è Image-based CSV format detected - this may need custom processing\")\n",
        "        # Add custom logic here based on your specific format\n",
        "    \n",
        "    def get_class_mapping(self):\n",
        "        \"\"\"Get the class name to ID mapping\"\"\"\n",
        "        return self.class_mapping\n",
        "    \n",
        "    def get_dataset_info(self):\n",
        "        \"\"\"Get dataset statistics\"\"\"\n",
        "        total_annotations = sum(len(anns) for anns in self.annotations.values())\n",
        "        class_counts = {}\n",
        "        \n",
        "        for anns in self.annotations.values():\n",
        "            for ann in anns:\n",
        "                class_name = ann['class_name']\n",
        "                class_counts[class_name] = class_counts.get(class_name, 0) + 1\n",
        "        \n",
        "        return {\n",
        "            'total_images': len(self.images),\n",
        "            'total_annotations': total_annotations,\n",
        "            'num_classes': len(self.class_mapping),\n",
        "            'class_counts': class_counts,\n",
        "            'avg_annotations_per_image': total_annotations / len(self.images) if self.images else 0\n",
        "        }\n",
        "\n",
        "# Initialize the data loader\n",
        "# Update this path to your data directory\n",
        "DATA_DIR = \"./your_data\"  # Change this to your actual data path\n",
        "\n",
        "# Create data loader\n",
        "data_loader = CSVDataLoader(DATA_DIR)\n",
        "\n",
        "# Load the data\n",
        "images, annotations = data_loader.load_data()\n",
        "\n",
        "# Get dataset information\n",
        "dataset_info = data_loader.get_dataset_info()\n",
        "print(f\"\\nüìä Dataset Information:\")\n",
        "print(f\"   Total images: {dataset_info['total_images']}\")\n",
        "print(f\"   Total annotations: {dataset_info['total_annotations']}\")\n",
        "print(f\"   Number of classes: {dataset_info['num_classes']}\")\n",
        "print(f\"   Average annotations per image: {dataset_info['avg_annotations_per_image']:.2f}\")\n",
        "\n",
        "print(f\"\\nüìã Class distribution:\")\n",
        "for class_name, count in dataset_info['class_counts'].items():\n",
        "    print(f\"   {class_name}: {count}\")\n",
        "\n",
        "print(f\"\\nüî¢ Class mapping:\")\n",
        "class_mapping = data_loader.get_class_mapping()\n",
        "for class_name, class_id in class_mapping.items():\n",
        "    print(f\"   {class_id}: {class_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Step 3: Data Visualization and Exploration\n",
        "\n",
        "Let's visualize some of your data to understand the annotations and ensure everything is loaded correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è No data loaded. Please check your DATA_DIR path and ensure you have images and CSV files.\n"
          ]
        }
      ],
      "source": [
        "def visualize_annotations(image_path, annotations, class_mapping, max_images=4):\n",
        "    \"\"\"\n",
        "    Visualize images with their annotations\n",
        "    \"\"\"\n",
        "    # Create a figure with subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    # Get a sample of images with annotations\n",
        "    annotated_images = [(img, anns) for img, anns in zip(images, [annotations.get(img.name, []) for img in images]) if anns]\n",
        "    \n",
        "    for i, (img_path, img_annotations) in enumerate(annotated_images[:max_images]):\n",
        "        if i >= len(axes):\n",
        "            break\n",
        "            \n",
        "        # Load image\n",
        "        image = cv2.imread(str(img_path))\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Draw annotations\n",
        "        for ann in img_annotations:\n",
        "            x, y, w, h = ann['x'], ann['y'], ann['width'], ann['height']\n",
        "            class_name = ann['class_name']\n",
        "            \n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(image, (int(x), int(y)), (int(x + w), int(y + h)), (255, 0, 0), 2)\n",
        "            \n",
        "            # Draw class label\n",
        "            cv2.putText(image, class_name, (int(x), int(y - 10)), \n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
        "        \n",
        "        # Display image\n",
        "        axes[i].imshow(image)\n",
        "        axes[i].set_title(f\"{img_path.name}\\n{len(img_annotations)} objects\")\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    # Hide unused subplots\n",
        "    for i in range(len(annotated_images), len(axes)):\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_class_distribution(class_counts):\n",
        "    \"\"\"Plot the distribution of classes\"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    classes = list(class_counts.keys())\n",
        "    counts = list(class_counts.values())\n",
        "    \n",
        "    bars = plt.bar(classes, counts, color='skyblue', edgecolor='navy', alpha=0.7)\n",
        "    plt.title('Class Distribution in Dataset', fontsize=16, fontweight='bold')\n",
        "    plt.xlabel('Class Names', fontsize=12)\n",
        "    plt.ylabel('Number of Annotations', fontsize=12)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar, count in zip(bars, counts):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
        "                str(count), ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_annotation_statistics(dataset_info):\n",
        "    \"\"\"Plot various annotation statistics\"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "    \n",
        "    # 1. Class distribution\n",
        "    classes = list(dataset_info['class_counts'].keys())\n",
        "    counts = list(dataset_info['class_counts'].values())\n",
        "    axes[0].pie(counts, labels=classes, autopct='%1.1f%%', startangle=90)\n",
        "    axes[0].set_title('Class Distribution (Pie Chart)')\n",
        "    \n",
        "    # 2. Total statistics\n",
        "    stats = ['Total Images', 'Total Annotations', 'Number of Classes']\n",
        "    values = [dataset_info['total_images'], dataset_info['total_annotations'], dataset_info['num_classes']]\n",
        "    bars = axes[1].bar(stats, values, color=['lightcoral', 'lightgreen', 'lightblue'])\n",
        "    axes[1].set_title('Dataset Statistics')\n",
        "    axes[1].set_ylabel('Count')\n",
        "    \n",
        "    # Add value labels\n",
        "    for bar, value in zip(bars, values):\n",
        "        axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
        "                    str(value), ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    # 3. Average annotations per image\n",
        "    axes[2].bar(['Avg Annotations/Image'], [dataset_info['avg_annotations_per_image']], \n",
        "               color='orange', alpha=0.7)\n",
        "    axes[2].set_title('Average Annotations per Image')\n",
        "    axes[2].set_ylabel('Count')\n",
        "    axes[2].text(0, dataset_info['avg_annotations_per_image'] + 0.1, \n",
        "                f\"{dataset_info['avg_annotations_per_image']:.2f}\", \n",
        "                ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize the data\n",
        "if len(images) > 0 and len(annotations) > 0:\n",
        "    print(\"üìä Visualizing sample images with annotations...\")\n",
        "    visualize_annotations(images[0], annotations, class_mapping)\n",
        "    \n",
        "    print(\"\\nüìà Plotting class distribution...\")\n",
        "    plot_class_distribution(dataset_info['class_counts'])\n",
        "    \n",
        "    print(\"\\nüìä Plotting dataset statistics...\")\n",
        "    plot_annotation_statistics(dataset_info)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No data loaded. Please check your DATA_DIR path and ensure you have images and CSV files.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Step 4: Convert CSV Annotations to YOLO Format\n",
        "\n",
        "Now we'll convert your CSV annotations to YOLO format and create the proper directory structure for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è No data to convert. Please ensure your data is loaded correctly.\n"
          ]
        }
      ],
      "source": [
        "class YOLODataConverter:\n",
        "    \"\"\"\n",
        "    Convert CSV annotations to YOLO format and create dataset structure\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, images, annotations, class_mapping, output_dir=\"./yolo_dataset\"):\n",
        "        self.images = images\n",
        "        self.annotations = annotations\n",
        "        self.class_mapping = class_mapping\n",
        "        self.output_dir = Path(output_dir)\n",
        "        \n",
        "    def create_yolo_structure(self):\n",
        "        \"\"\"Create YOLO dataset directory structure\"\"\"\n",
        "        directories = [\n",
        "            'images/train',\n",
        "            'images/val',\n",
        "            'images/test',\n",
        "            'labels/train',\n",
        "            'labels/val',\n",
        "            'labels/test'\n",
        "        ]\n",
        "        \n",
        "        for directory in directories:\n",
        "            full_path = self.output_dir / directory\n",
        "            full_path.mkdir(parents=True, exist_ok=True)\n",
        "            print(f\"‚úÖ Created directory: {full_path}\")\n",
        "    \n",
        "    def convert_to_yolo_format(self, train_split=0.7, val_split=0.2, test_split=0.1):\n",
        "        \"\"\"\n",
        "        Convert CSV annotations to YOLO format and split data\n",
        "        \"\"\"\n",
        "        print(f\"üîÑ Converting annotations to YOLO format...\")\n",
        "        print(f\"üìä Split ratios - Train: {train_split}, Val: {val_split}, Test: {test_split}\")\n",
        "        \n",
        "        # Create directory structure\n",
        "        self.create_yolo_structure()\n",
        "        \n",
        "        # Get images with annotations\n",
        "        annotated_images = []\n",
        "        for img_path in self.images:\n",
        "            img_name = img_path.name\n",
        "            if img_name in self.annotations:\n",
        "                annotated_images.append((img_path, self.annotations[img_name]))\n",
        "        \n",
        "        print(f\"üì∏ Processing {len(annotated_images)} annotated images...\")\n",
        "        \n",
        "        # Split data\n",
        "        train_data, temp_data = train_test_split(\n",
        "            annotated_images, \n",
        "            train_size=train_split, \n",
        "            random_state=42\n",
        "        )\n",
        "        \n",
        "        val_data, test_data = train_test_split(\n",
        "            temp_data, \n",
        "            train_size=val_split/(val_split + test_split), \n",
        "            random_state=42\n",
        "        )\n",
        "        \n",
        "        print(f\"üìä Data split:\")\n",
        "        print(f\"   Train: {len(train_data)} images\")\n",
        "        print(f\"   Validation: {len(val_data)} images\")\n",
        "        print(f\"   Test: {len(test_data)} images\")\n",
        "        \n",
        "        # Process each split\n",
        "        splits = {\n",
        "            'train': train_data,\n",
        "            'val': val_data,\n",
        "            'test': test_data\n",
        "        }\n",
        "        \n",
        "        for split_name, split_data in splits.items():\n",
        "            print(f\"\\nüîÑ Processing {split_name} split...\")\n",
        "            self._process_split(split_name, split_data)\n",
        "        \n",
        "        # Create dataset.yaml\n",
        "        self._create_dataset_yaml()\n",
        "        \n",
        "        print(f\"\\n‚úÖ YOLO dataset created successfully in: {self.output_dir}\")\n",
        "    \n",
        "    def _process_split(self, split_name, split_data):\n",
        "        \"\"\"Process a single data split\"\"\"\n",
        "        for img_path, img_annotations in split_data:\n",
        "            # Copy image\n",
        "            img_dest = self.output_dir / f\"images/{split_name}\" / img_path.name\n",
        "            shutil.copy2(img_path, img_dest)\n",
        "            \n",
        "            # Convert annotations to YOLO format\n",
        "            yolo_annotations = self._convert_annotations_to_yolo(img_path, img_annotations)\n",
        "            \n",
        "            # Save YOLO labels\n",
        "            label_dest = self.output_dir / f\"labels/{split_name}\" / f\"{img_path.stem}.txt\"\n",
        "            self._save_yolo_labels(yolo_annotations, label_dest)\n",
        "    \n",
        "    def _convert_annotations_to_yolo(self, img_path, annotations):\n",
        "        \"\"\"Convert CSV annotations to YOLO format\"\"\"\n",
        "        # Load image to get dimensions\n",
        "        image = cv2.imread(str(img_path))\n",
        "        img_height, img_width = image.shape[:2]\n",
        "        \n",
        "        yolo_annotations = []\n",
        "        \n",
        "        for ann in annotations:\n",
        "            # Get absolute coordinates\n",
        "            x_abs = ann['x']\n",
        "            y_abs = ann['y']\n",
        "            w_abs = ann['width']\n",
        "            h_abs = ann['height']\n",
        "            \n",
        "            # Convert to YOLO format (normalized center coordinates and dimensions)\n",
        "            center_x = (x_abs + w_abs / 2) / img_width\n",
        "            center_y = (y_abs + h_abs / 2) / img_height\n",
        "            width = w_abs / img_width\n",
        "            height = h_abs / img_height\n",
        "            \n",
        "            # Ensure coordinates are within [0, 1]\n",
        "            center_x = max(0, min(1, center_x))\n",
        "            center_y = max(0, min(1, center_y))\n",
        "            width = max(0, min(1, width))\n",
        "            height = max(0, min(1, height))\n",
        "            \n",
        "            yolo_annotation = [\n",
        "                ann['class_id'],\n",
        "                center_x,\n",
        "                center_y,\n",
        "                width,\n",
        "                height\n",
        "            ]\n",
        "            \n",
        "            yolo_annotations.append(yolo_annotation)\n",
        "        \n",
        "        return yolo_annotations\n",
        "    \n",
        "    def _save_yolo_labels(self, yolo_annotations, output_file):\n",
        "        \"\"\"Save YOLO format labels to file\"\"\"\n",
        "        with open(output_file, 'w') as f:\n",
        "            for ann in yolo_annotations:\n",
        "                line = ' '.join([str(x) for x in ann])\n",
        "                f.write(line + '\\n')\n",
        "    \n",
        "    def _create_dataset_yaml(self):\n",
        "        \"\"\"Create dataset.yaml file for YOLO training\"\"\"\n",
        "        # Sort class names by their IDs\n",
        "        sorted_classes = sorted(self.class_mapping.items(), key=lambda x: x[1])\n",
        "        class_names = [name for name, _ in sorted_classes]\n",
        "        \n",
        "        yaml_content = {\n",
        "            'path': str(self.output_dir.absolute()),\n",
        "            'train': 'images/train',\n",
        "            'val': 'images/val',\n",
        "            'test': 'images/test',\n",
        "            'nc': len(self.class_mapping),\n",
        "            'names': class_names\n",
        "        }\n",
        "        \n",
        "        yaml_path = self.output_dir / 'dataset.yaml'\n",
        "        with open(yaml_path, 'w') as f:\n",
        "            yaml.dump(yaml_content, f, default_flow_style=False, sort_keys=False)\n",
        "        \n",
        "        print(f\"‚úÖ Created dataset.yaml: {yaml_path}\")\n",
        "        print(f\"üìã Classes: {class_names}\")\n",
        "        \n",
        "        return yaml_path\n",
        "\n",
        "# Convert data to YOLO format\n",
        "if len(images) > 0 and len(annotations) > 0:\n",
        "    print(\"üîÑ Converting CSV data to YOLO format...\")\n",
        "    \n",
        "    converter = YOLODataConverter(images, annotations, class_mapping, output_dir=\"./yolo_dataset\")\n",
        "    converter.convert_to_yolo_format(\n",
        "        train_split=0.7,\n",
        "        val_split=0.2, \n",
        "        test_split=0.1\n",
        "    )\n",
        "    \n",
        "    print(\"\\n‚úÖ Data conversion completed!\")\n",
        "    print(\"üìÅ YOLO dataset structure created in './yolo_dataset'\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No data to convert. Please ensure your data is loaded correctly.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Step 5: Model Training\n",
        "\n",
        "Now let's train the YOLO model on your converted dataset. We'll use YOLOv9 with biomedical-optimized settings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class YOLOTrainer:\n",
        "    \"\"\"\n",
        "    YOLO model trainer with biomedical-optimized settings\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, dataset_path, model_name=\"yolov9c.pt\"):\n",
        "        self.dataset_path = dataset_path\n",
        "        self.model_name = model_name\n",
        "        self.model = None\n",
        "        \n",
        "    def setup_model(self):\n",
        "        \"\"\"Initialize YOLO model\"\"\"\n",
        "        print(f\"üîç Loading YOLO model: {self.model_name}\")\n",
        "        self.model = YOLO(self.model_name)\n",
        "        print(\"‚úÖ Model loaded successfully\")\n",
        "        \n",
        "        # Print model info\n",
        "        print(f\"üìä Model information:\")\n",
        "        print(f\"   Model: {self.model_name}\")\n",
        "        print(f\"   Task: {self.model.task}\")\n",
        "        print(f\"   Classes: {len(self.model.names)}\")\n",
        "        \n",
        "    def train(self, epochs=100, batch_size=16, img_size=640, device=0, \n",
        "              project=\"biomedical_yolo\", name=\"exp\", **kwargs):\n",
        "        \"\"\"\n",
        "        Train the YOLO model with custom parameters\n",
        "        \"\"\"\n",
        "        if self.model is None:\n",
        "            self.setup_model()\n",
        "        \n",
        "        print(f\"üöÄ Starting training...\")\n",
        "        print(f\"üìä Training parameters:\")\n",
        "        print(f\"   Epochs: {epochs}\")\n",
        "        print(f\"   Batch size: {batch_size}\")\n",
        "        print(f\"   Image size: {img_size}\")\n",
        "        print(f\"   Device: {device}\")\n",
        "        print(f\"   Project: {project}\")\n",
        "        print(f\"   Name: {name}\")\n",
        "        \n",
        "        # Training configuration optimized for biomedical data\n",
        "        training_config = {\n",
        "            'data': self.dataset_path,\n",
        "            'epochs': epochs,\n",
        "            'imgsz': img_size,\n",
        "            'batch': batch_size,\n",
        "            'device': device,\n",
        "            'project': project,\n",
        "            'name': name,\n",
        "            'exist_ok': True,\n",
        "            'pretrained': True,\n",
        "            'optimizer': 'auto',\n",
        "            'verbose': True,\n",
        "            'seed': 42,\n",
        "            'deterministic': True,\n",
        "            'single_cls': False,\n",
        "            'rect': False,\n",
        "            'cos_lr': False,\n",
        "            'close_mosaic': 10,\n",
        "            'resume': False,\n",
        "            'amp': True,\n",
        "            'fraction': 1.0,\n",
        "            'cache': False,\n",
        "            'overlap_mask': True,\n",
        "            'mask_ratio': 4,\n",
        "            'dropout': 0.0,\n",
        "            'val': True,\n",
        "            'plots': True,\n",
        "            'save_period': 10,\n",
        "            \n",
        "            # Biomedical-optimized augmentation settings\n",
        "            'hsv_h': 0.01,      # Minimal hue change for medical images\n",
        "            'hsv_s': 0.3,       # Reduced saturation change\n",
        "            'hsv_v': 0.2,       # Reduced brightness change\n",
        "            'degrees': 0.0,     # No rotation (preserve orientation)\n",
        "            'translate': 0.1,   # Small translation\n",
        "            'scale': 0.3,       # Reduced scaling\n",
        "            'shear': 0.0,       # No shearing\n",
        "            'perspective': 0.0, # No perspective distortion\n",
        "            'flipud': 0.0,      # No vertical flip\n",
        "            'fliplr': 0.3,      # Reduced horizontal flip\n",
        "            'mosaic': 0.8,      # Reduced mosaic augmentation\n",
        "            'mixup': 0.0,       # No mixup for medical images\n",
        "            \n",
        "            # Loss weights\n",
        "            'box': 7.5,\n",
        "            'cls': 0.5,\n",
        "            'dfl': 1.5,\n",
        "            \n",
        "            # Learning rate settings\n",
        "            'lr0': 0.01,\n",
        "            'lrf': 0.01,\n",
        "            'momentum': 0.937,\n",
        "            'weight_decay': 0.0005,\n",
        "            'warmup_epochs': 3.0,\n",
        "            'warmup_momentum': 0.8,\n",
        "            'warmup_bias_lr': 0.1,\n",
        "        }\n",
        "        \n",
        "        # Update with any custom parameters\n",
        "        training_config.update(kwargs)\n",
        "        \n",
        "        try:\n",
        "            # Start training\n",
        "            results = self.model.train(**training_config)\n",
        "            \n",
        "            print(\"‚úÖ Training completed successfully!\")\n",
        "            return results\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Training failed: {str(e)}\")\n",
        "            return None\n",
        "    \n",
        "    def get_training_results(self, results):\n",
        "        \"\"\"Extract and display training results\"\"\"\n",
        "        if results is None:\n",
        "            print(\"‚ùå No training results available\")\n",
        "            return\n",
        "        \n",
        "        print(f\"\\nüìä Training Results:\")\n",
        "        print(f\"   Best model saved at: {results.save_dir}\")\n",
        "        print(f\"   Training completed in: {results.epochs} epochs\")\n",
        "        \n",
        "        # Get final metrics\n",
        "        if hasattr(results, 'results_dict'):\n",
        "            metrics = results.results_dict\n",
        "            print(f\"   Final mAP@0.5: {metrics.get('metrics/mAP50(B)', 'N/A')}\")\n",
        "            print(f\"   Final mAP@0.5:0.95: {metrics.get('metrics/mAP50-95(B)', 'N/A')}\")\n",
        "            \n",
        "            if 'seg' in metrics:\n",
        "                print(f\"   Segmentation mAP@0.5: {metrics.get('metrics/mAP50(S)', 'N/A')}\")\n",
        "                print(f\"   Segmentation mAP@0.5:0.95: {metrics.get('metrics/mAP50-95(S)', 'N/A')}\")\n",
        "\n",
        "# Training configuration\n",
        "TRAINING_CONFIG = {\n",
        "    'epochs': 100,           # Number of training epochs\n",
        "    'batch_size': 16,        # Batch size (reduce if you get CUDA out of memory)\n",
        "    'img_size': 640,         # Input image size\n",
        "    'device': 0,             # GPU device (use 'cpu' for CPU training)\n",
        "    'project': 'biomedical_yolo',\n",
        "    'name': 'csv_training'\n",
        "}\n",
        "\n",
        "# Check if dataset exists\n",
        "dataset_yaml_path = \"./yolo_dataset/dataset.yaml\"\n",
        "if os.path.exists(dataset_yaml_path):\n",
        "    print(f\"‚úÖ Dataset found: {dataset_yaml_path}\")\n",
        "    \n",
        "    # Initialize trainer\n",
        "    trainer = YOLOTrainer(dataset_yaml_path, model_name=\"yolov9c.pt\")\n",
        "    \n",
        "    # Start training\n",
        "    print(\"üöÄ Starting YOLO training...\")\n",
        "    results = trainer.train(**TRAINING_CONFIG)\n",
        "    \n",
        "    # Display results\n",
        "    trainer.get_training_results(results)\n",
        "    \n",
        "    # Save best model path for later use\n",
        "    if results:\n",
        "        best_model_path = results.save_dir / \"weights\" / \"best.pt\"\n",
        "        print(f\"\\nüíæ Best model saved at: {best_model_path}\")\n",
        "        \n",
        "        # Save model path to a file for easy access\n",
        "        with open(\"best_model_path.txt\", \"w\") as f:\n",
        "            f.write(str(best_model_path))\n",
        "        print(\"üìù Model path saved to 'best_model_path.txt'\")\n",
        "        \n",
        "else:\n",
        "    print(f\"‚ùå Dataset not found: {dataset_yaml_path}\")\n",
        "    print(\"Please ensure you have run the data conversion step first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Step 6: Model Inference and Testing\n",
        "\n",
        "Let's test our trained model on some sample images to see how it performs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class YOLOInference:\n",
        "    \"\"\"\n",
        "    YOLO model inference for testing and prediction\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model_path, conf_threshold=0.25, iou_threshold=0.45):\n",
        "        self.model_path = model_path\n",
        "        self.conf_threshold = conf_threshold\n",
        "        self.iou_threshold = iou_threshold\n",
        "        self.model = None\n",
        "        \n",
        "    def load_model(self):\n",
        "        \"\"\"Load the trained YOLO model\"\"\"\n",
        "        print(f\"üîç Loading model from: {self.model_path}\")\n",
        "        self.model = YOLO(self.model_path)\n",
        "        print(\"‚úÖ Model loaded successfully\")\n",
        "        \n",
        "        # Get model info\n",
        "        print(f\"üìä Model information:\")\n",
        "        print(f\"   Classes: {list(self.model.names.values())}\")\n",
        "        print(f\"   Confidence threshold: {self.conf_threshold}\")\n",
        "        print(f\"   IoU threshold: {self.iou_threshold}\")\n",
        "    \n",
        "    def predict_single_image(self, image_path, save_results=True, output_dir=\"./inference_results\"):\n",
        "        \"\"\"Run inference on a single image\"\"\"\n",
        "        if self.model is None:\n",
        "            self.load_model()\n",
        "        \n",
        "        print(f\"üîç Processing image: {image_path}\")\n",
        "        \n",
        "        # Run inference\n",
        "        results = self.model(\n",
        "            image_path,\n",
        "            conf=self.conf_threshold,\n",
        "            iou=self.iou_threshold,\n",
        "            verbose=False\n",
        "        )\n",
        "        \n",
        "        # Process results\n",
        "        processed_results = self._process_results(results[0], image_path)\n",
        "        \n",
        "        # Save results if requested\n",
        "        if save_results:\n",
        "            self._save_results(processed_results, image_path, output_dir)\n",
        "        \n",
        "        return processed_results\n",
        "    \n",
        "    def predict_batch(self, image_dir, save_results=True, output_dir=\"./inference_results\"):\n",
        "        \"\"\"Run inference on a batch of images\"\"\"\n",
        "        if self.model is None:\n",
        "            self.load_model()\n",
        "        \n",
        "        print(f\"üîç Processing batch from: {image_dir}\")\n",
        "        \n",
        "        # Get all image files\n",
        "        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']\n",
        "        image_files = []\n",
        "        \n",
        "        for ext in image_extensions:\n",
        "            image_files.extend(Path(image_dir).glob(f\"*{ext}\"))\n",
        "            image_files.extend(Path(image_dir).glob(f\"*{ext.upper()}\"))\n",
        "        \n",
        "        if not image_files:\n",
        "            print(f\"‚ùå No images found in {image_dir}\")\n",
        "            return []\n",
        "        \n",
        "        print(f\"üì∏ Found {len(image_files)} images\")\n",
        "        \n",
        "        # Process each image\n",
        "        all_results = []\n",
        "        for i, image_path in enumerate(image_files):\n",
        "            print(f\"üîÑ Processing {i+1}/{len(image_files)}: {image_path.name}\")\n",
        "            try:\n",
        "                result = self.predict_single_image(str(image_path), save_results, output_dir)\n",
        "                all_results.append(result)\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Error processing {image_path.name}: {str(e)}\")\n",
        "                continue\n",
        "        \n",
        "        return all_results\n",
        "    \n",
        "    def _process_results(self, result, image_path):\n",
        "        \"\"\"Process YOLO results into a structured format\"\"\"\n",
        "        processed = {\n",
        "            'image_path': image_path,\n",
        "            'image_shape': result.orig_shape,\n",
        "            'detections': [],\n",
        "            'summary': {}\n",
        "        }\n",
        "        \n",
        "        # Process detections\n",
        "        if result.boxes is not None:\n",
        "            boxes = result.boxes.xyxy.cpu().numpy()\n",
        "            confidences = result.boxes.conf.cpu().numpy()\n",
        "            class_ids = result.boxes.cls.cpu().numpy().astype(int)\n",
        "            \n",
        "            for i in range(len(boxes)):\n",
        "                detection = {\n",
        "                    'bbox': boxes[i].tolist(),  # [x1, y1, x2, y2]\n",
        "                    'confidence': float(confidences[i]),\n",
        "                    'class_id': int(class_ids[i]),\n",
        "                    'class_name': self.model.names[int(class_ids[i])]\n",
        "                }\n",
        "                processed['detections'].append(detection)\n",
        "        \n",
        "        # Add summary statistics\n",
        "        processed['summary'] = {\n",
        "            'total_detections': len(processed['detections']),\n",
        "            'classes_detected': list(set([d['class_name'] for d in processed['detections']])),\n",
        "            'confidence_range': {\n",
        "                'min': min([d['confidence'] for d in processed['detections']]) if processed['detections'] else 0,\n",
        "                'max': max([d['confidence'] for d in processed['detections']]) if processed['detections'] else 0\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        return processed\n",
        "    \n",
        "    def _save_results(self, results, image_path, output_dir):\n",
        "        \"\"\"Save inference results\"\"\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        \n",
        "        # Save JSON results\n",
        "        base_name = Path(image_path).stem\n",
        "        json_path = os.path.join(output_dir, f\"{base_name}_results.json\")\n",
        "        \n",
        "        with open(json_path, 'w') as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "        \n",
        "        # Save annotated image\n",
        "        annotated_image = self._create_annotated_image(image_path, results)\n",
        "        image_output_path = os.path.join(output_dir, f\"{base_name}_annotated.jpg\")\n",
        "        annotated_image.save(image_output_path)\n",
        "        \n",
        "        print(f\"üíæ Results saved to: {output_dir}\")\n",
        "    \n",
        "    def _create_annotated_image(self, image_path, results):\n",
        "        \"\"\"Create annotated image with bounding boxes and labels\"\"\"\n",
        "        # Load image\n",
        "        image = Image.open(image_path)\n",
        "        draw = ImageDraw.Draw(image)\n",
        "        \n",
        "        # Try to load a font, fall back to default if not available\n",
        "        try:\n",
        "            font = ImageFont.truetype(\"arial.ttf\", 16)\n",
        "        except:\n",
        "            font = ImageFont.load_default()\n",
        "        \n",
        "        # Draw detections\n",
        "        for detection in results['detections']:\n",
        "            bbox = detection['bbox']\n",
        "            class_name = detection['class_name']\n",
        "            confidence = detection['confidence']\n",
        "            \n",
        "            # Draw bounding box\n",
        "            x1, y1, x2, y2 = bbox\n",
        "            draw.rectangle([x1, y1, x2, y2], outline='red', width=3)\n",
        "            \n",
        "            # Draw label\n",
        "            label = f\"{class_name}: {confidence:.2f}\"\n",
        "            label_bbox = draw.textbbox((0, 0), label, font=font)\n",
        "            label_width = label_bbox[2] - label_bbox[0]\n",
        "            label_height = label_bbox[3] - label_bbox[1]\n",
        "            \n",
        "            # Draw label background\n",
        "            draw.rectangle([x1, y1-label_height-5, x1+label_width+10, y1], fill='red')\n",
        "            \n",
        "            # Draw label text\n",
        "            draw.text((x1+5, y1-label_height-2), label, fill='white', font=font)\n",
        "        \n",
        "        return image\n",
        "\n",
        "def visualize_inference_results(results, max_images=4):\n",
        "    \"\"\"Visualize inference results\"\"\"\n",
        "    if not results:\n",
        "        print(\"No results to visualize\")\n",
        "        return\n",
        "    \n",
        "    # Get sample results\n",
        "    sample_results = results[:max_images]\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for i, result in enumerate(sample_results):\n",
        "        if i >= len(axes):\n",
        "            break\n",
        "        \n",
        "        # Load original image\n",
        "        image = cv2.imread(result['image_path'])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Draw detections\n",
        "        for detection in result['detections']:\n",
        "            bbox = detection['bbox']\n",
        "            class_name = detection['class_name']\n",
        "            confidence = detection['confidence']\n",
        "            \n",
        "            x1, y1, x2, y2 = [int(coord) for coord in bbox]\n",
        "            \n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "            \n",
        "            # Draw label\n",
        "            label = f\"{class_name}: {confidence:.2f}\"\n",
        "            cv2.putText(image, label, (x1, y1 - 10), \n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
        "        \n",
        "        # Display image\n",
        "        axes[i].imshow(image)\n",
        "        axes[i].set_title(f\"{Path(result['image_path']).name}\\n{result['summary']['total_detections']} detections\")\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    # Hide unused subplots\n",
        "    for i in range(len(sample_results), len(axes)):\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Test inference on trained model\n",
        "if os.path.exists(\"best_model_path.txt\"):\n",
        "    with open(\"best_model_path.txt\", \"r\") as f:\n",
        "        model_path = f.read().strip()\n",
        "    \n",
        "    if os.path.exists(model_path):\n",
        "        print(f\"‚úÖ Found trained model: {model_path}\")\n",
        "        \n",
        "        # Initialize inference\n",
        "        inference = YOLOInference(model_path, conf_threshold=0.25, iou_threshold=0.45)\n",
        "        \n",
        "        # Test on validation images\n",
        "        val_images_dir = \"./yolo_dataset/images/val\"\n",
        "        if os.path.exists(val_images_dir):\n",
        "            print(\"üîç Running inference on validation images...\")\n",
        "            results = inference.predict_batch(val_images_dir, save_results=True)\n",
        "            \n",
        "            if results:\n",
        "                print(f\"\\nüìä Inference Results Summary:\")\n",
        "                total_detections = sum(r['summary']['total_detections'] for r in results)\n",
        "                print(f\"   Processed {len(results)} images\")\n",
        "                print(f\"   Total detections: {total_detections}\")\n",
        "                print(f\"   Average detections per image: {total_detections/len(results):.2f}\")\n",
        "                \n",
        "                # Visualize results\n",
        "                print(\"\\nüìä Visualizing inference results...\")\n",
        "                visualize_inference_results(results)\n",
        "            else:\n",
        "                print(\"‚ùå No inference results generated\")\n",
        "        else:\n",
        "            print(f\"‚ùå Validation images directory not found: {val_images_dir}\")\n",
        "    else:\n",
        "        print(f\"‚ùå Model file not found: {model_path}\")\n",
        "else:\n",
        "    print(\"‚ùå No trained model found. Please run the training step first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Step 7: Model Evaluation and Performance Analysis\n",
        "\n",
        "Let's evaluate our trained model's performance on the test set and generate comprehensive metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class YOLOEvaluator:\n",
        "    \"\"\"\n",
        "    Comprehensive YOLO model evaluation\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model_path, dataset_path, conf_threshold=0.25, iou_threshold=0.45):\n",
        "        self.model_path = model_path\n",
        "        self.dataset_path = dataset_path\n",
        "        self.conf_threshold = conf_threshold\n",
        "        self.iou_threshold = iou_threshold\n",
        "        self.model = None\n",
        "        self.class_names = None\n",
        "        \n",
        "    def load_model_and_dataset(self):\n",
        "        \"\"\"Load model and dataset information\"\"\"\n",
        "        print(f\"üîç Loading model from: {self.model_path}\")\n",
        "        self.model = YOLO(self.model_path)\n",
        "        \n",
        "        # Load dataset info\n",
        "        with open(self.dataset_path, 'r') as f:\n",
        "            dataset_info = yaml.safe_load(f)\n",
        "        \n",
        "        self.class_names = dataset_info['names']\n",
        "        self.dataset_root = Path(dataset_info['path'])\n",
        "        \n",
        "        print(f\"‚úÖ Model and dataset loaded successfully\")\n",
        "        print(f\"üìã Classes: {self.class_names}\")\n",
        "    \n",
        "    def evaluate_model(self, output_dir=\"./evaluation_results\"):\n",
        "        \"\"\"Run comprehensive model evaluation\"\"\"\n",
        "        if self.model is None:\n",
        "            self.load_model_and_dataset()\n",
        "        \n",
        "        print(\"üöÄ Starting model evaluation...\")\n",
        "        \n",
        "        # Create output directory\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        \n",
        "        # Get test images\n",
        "        test_images_dir = self.dataset_root / \"images/test\"\n",
        "        test_labels_dir = self.dataset_root / \"labels/test\"\n",
        "        \n",
        "        if not test_images_dir.exists():\n",
        "            print(\"‚ùå Test images directory not found\")\n",
        "            return\n",
        "        \n",
        "        test_images = list(test_images_dir.glob(\"*.jpg\")) + list(test_images_dir.glob(\"*.png\"))\n",
        "        \n",
        "        if not test_images:\n",
        "            print(\"‚ùå No test images found\")\n",
        "            return\n",
        "        \n",
        "        print(f\"üì∏ Found {len(test_images)} test images\")\n",
        "        \n",
        "        # Run predictions and collect ground truth\n",
        "        all_predictions = []\n",
        "        all_ground_truth = []\n",
        "        \n",
        "        for i, img_path in enumerate(test_images):\n",
        "            print(f\"üîÑ Processing {i+1}/{len(test_images)}: {img_path.name}\")\n",
        "            \n",
        "            # Get ground truth\n",
        "            gt_path = test_labels_dir / f\"{img_path.stem}.txt\"\n",
        "            ground_truth = self._load_ground_truth(gt_path, img_path)\n",
        "            \n",
        "            # Run prediction\n",
        "            predictions = self._run_prediction(img_path)\n",
        "            \n",
        "            # Store results\n",
        "            all_predictions.append(predictions)\n",
        "            all_ground_truth.append(ground_truth)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        evaluation_results = self._calculate_metrics(all_predictions, all_ground_truth)\n",
        "        \n",
        "        # Generate reports\n",
        "        self._generate_reports(evaluation_results, output_dir)\n",
        "        \n",
        "        # Create visualizations\n",
        "        self._create_visualizations(evaluation_results, output_dir)\n",
        "        \n",
        "        print(f\"‚úÖ Evaluation completed! Results saved to: {output_dir}\")\n",
        "        return evaluation_results\n",
        "    \n",
        "    def _load_ground_truth(self, label_path, image_path):\n",
        "        \"\"\"Load ground truth annotations\"\"\"\n",
        "        ground_truth = []\n",
        "        \n",
        "        if not label_path.exists():\n",
        "            return ground_truth\n",
        "        \n",
        "        # Load image dimensions\n",
        "        img = cv2.imread(str(image_path))\n",
        "        img_height, img_width = img.shape[:2]\n",
        "        \n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) == 5:\n",
        "                    class_id = int(parts[0])\n",
        "                    center_x = float(parts[1])\n",
        "                    center_y = float(parts[2])\n",
        "                    width = float(parts[3])\n",
        "                    height = float(parts[4])\n",
        "                    \n",
        "                    # Convert to absolute coordinates\n",
        "                    x1 = (center_x - width/2) * img_width\n",
        "                    y1 = (center_y - height/2) * img_height\n",
        "                    x2 = (center_x + width/2) * img_width\n",
        "                    y2 = (center_y + height/2) * img_height\n",
        "                    \n",
        "                    ground_truth.append({\n",
        "                        'class_id': class_id,\n",
        "                        'bbox': [x1, y1, x2, y2],\n",
        "                        'class_name': self.class_names[class_id]\n",
        "                    })\n",
        "        \n",
        "        return ground_truth\n",
        "    \n",
        "    def _run_prediction(self, image_path):\n",
        "        \"\"\"Run model prediction on single image\"\"\"\n",
        "        results = self.model(\n",
        "            str(image_path),\n",
        "            conf=self.conf_threshold,\n",
        "            iou=self.iou_threshold,\n",
        "            verbose=False\n",
        "        )\n",
        "        \n",
        "        predictions = []\n",
        "        if results[0].boxes is not None:\n",
        "            boxes = results[0].boxes.xyxy.cpu().numpy()\n",
        "            confidences = results[0].boxes.conf.cpu().numpy()\n",
        "            class_ids = results[0].boxes.cls.cpu().numpy().astype(int)\n",
        "            \n",
        "            for i in range(len(boxes)):\n",
        "                predictions.append({\n",
        "                    'class_id': int(class_ids[i]),\n",
        "                    'bbox': boxes[i].tolist(),\n",
        "                    'confidence': float(confidences[i]),\n",
        "                    'class_name': self.class_names[int(class_ids[i])]\n",
        "                })\n",
        "        \n",
        "        return predictions\n",
        "    \n",
        "    def _calculate_metrics(self, predictions, ground_truth):\n",
        "        \"\"\"Calculate evaluation metrics\"\"\"\n",
        "        print(\"üìä Calculating evaluation metrics...\")\n",
        "        \n",
        "        # Initialize metrics storage\n",
        "        class_metrics = {i: {'tp': 0, 'fp': 0, 'fn': 0} for i in range(len(self.class_names))}\n",
        "        \n",
        "        # Calculate IoU and assign predictions to ground truth\n",
        "        for pred_list, gt_list in zip(predictions, ground_truth):\n",
        "            # For each ground truth, find best matching prediction\n",
        "            for gt in gt_list:\n",
        "                best_iou = 0\n",
        "                best_pred_idx = -1\n",
        "                \n",
        "                for i, pred in enumerate(pred_list):\n",
        "                    if pred['class_id'] == gt['class_id']:\n",
        "                        iou = self._calculate_iou(gt['bbox'], pred['bbox'])\n",
        "                        if iou > best_iou and iou >= self.iou_threshold:\n",
        "                            best_iou = iou\n",
        "                            best_pred_idx = i\n",
        "                \n",
        "                if best_pred_idx >= 0:\n",
        "                    class_metrics[gt['class_id']]['tp'] += 1\n",
        "                    # Remove matched prediction\n",
        "                    pred_list.pop(best_pred_idx)\n",
        "                else:\n",
        "                    class_metrics[gt['class_id']]['fn'] += 1\n",
        "            \n",
        "            # Remaining predictions are false positives\n",
        "            for pred in pred_list:\n",
        "                class_metrics[pred['class_id']]['fp'] += 1\n",
        "        \n",
        "        # Calculate per-class metrics\n",
        "        evaluation_results = {}\n",
        "        for class_id in range(len(self.class_names)):\n",
        "            tp = class_metrics[class_id]['tp']\n",
        "            fp = class_metrics[class_id]['fp']\n",
        "            fn = class_metrics[class_id]['fn']\n",
        "            \n",
        "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "            \n",
        "            evaluation_results[self.class_names[class_id]] = {\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1_score': f1,\n",
        "                'true_positives': tp,\n",
        "                'false_positives': fp,\n",
        "                'false_negatives': fn\n",
        "            }\n",
        "        \n",
        "        # Calculate overall metrics\n",
        "        total_tp = sum(class_metrics[c]['tp'] for c in range(len(self.class_names)))\n",
        "        total_fp = sum(class_metrics[c]['fp'] for c in range(len(self.class_names)))\n",
        "        total_fn = sum(class_metrics[c]['fn'] for c in range(len(self.class_names)))\n",
        "        \n",
        "        overall_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
        "        overall_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
        "        overall_f1 = 2 * (overall_precision * overall_recall) / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0\n",
        "        \n",
        "        evaluation_results['overall'] = {\n",
        "            'precision': overall_precision,\n",
        "            'recall': overall_recall,\n",
        "            'f1_score': overall_f1,\n",
        "            'true_positives': total_tp,\n",
        "            'false_positives': total_fp,\n",
        "            'false_negatives': total_fn\n",
        "        }\n",
        "        \n",
        "        return evaluation_results\n",
        "    \n",
        "    def _calculate_iou(self, bbox1, bbox2):\n",
        "        \"\"\"Calculate Intersection over Union between two bounding boxes\"\"\"\n",
        "        x1_1, y1_1, x2_1, y2_1 = bbox1\n",
        "        x1_2, y1_2, x2_2, y2_2 = bbox2\n",
        "        \n",
        "        # Calculate intersection\n",
        "        x1_i = max(x1_1, x1_2)\n",
        "        y1_i = max(y1_1, y1_2)\n",
        "        x2_i = min(x2_1, x2_2)\n",
        "        y2_i = min(y2_1, y2_2)\n",
        "        \n",
        "        if x2_i <= x1_i or y2_i <= y1_i:\n",
        "            return 0.0\n",
        "        \n",
        "        intersection = (x2_i - x1_i) * (y2_i - y1_i)\n",
        "        \n",
        "        # Calculate union\n",
        "        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
        "        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
        "        union = area1 + area2 - intersection\n",
        "        \n",
        "        return intersection / union if union > 0 else 0.0\n",
        "    \n",
        "    def _generate_reports(self, evaluation_results, output_dir):\n",
        "        \"\"\"Generate evaluation reports\"\"\"\n",
        "        print(\"üìù Generating evaluation reports...\")\n",
        "        \n",
        "        # Save detailed results\n",
        "        results_file = os.path.join(output_dir, \"evaluation_results.json\")\n",
        "        with open(results_file, 'w') as f:\n",
        "            json.dump(evaluation_results, f, indent=2)\n",
        "        \n",
        "        # Create summary report\n",
        "        summary_file = os.path.join(output_dir, \"evaluation_summary.txt\")\n",
        "        with open(summary_file, 'w') as f:\n",
        "            f.write(\"YOLO Biomedical Object Detection - Evaluation Summary\\n\")\n",
        "            f.write(\"=\" * 60 + \"\\n\\n\")\n",
        "            \n",
        "            f.write(\"Overall Performance:\\n\")\n",
        "            overall = evaluation_results['overall']\n",
        "            f.write(f\"  Precision: {overall['precision']:.4f}\\n\")\n",
        "            f.write(f\"  Recall: {overall['recall']:.4f}\\n\")\n",
        "            f.write(f\"  F1-Score: {overall['f1_score']:.4f}\\n\")\n",
        "            f.write(f\"  True Positives: {overall['true_positives']}\\n\")\n",
        "            f.write(f\"  False Positives: {overall['false_positives']}\\n\")\n",
        "            f.write(f\"  False Negatives: {overall['false_negatives']}\\n\\n\")\n",
        "            \n",
        "            f.write(\"Per-Class Performance:\\n\")\n",
        "            for class_name, metrics in evaluation_results.items():\n",
        "                if class_name != 'overall':\n",
        "                    f.write(f\"  {class_name}:\\n\")\n",
        "                    f.write(f\"    Precision: {metrics['precision']:.4f}\\n\")\n",
        "                    f.write(f\"    Recall: {metrics['recall']:.4f}\\n\")\n",
        "                    f.write(f\"    F1-Score: {metrics['f1_score']:.4f}\\n\")\n",
        "                    f.write(f\"    TP: {metrics['true_positives']}, FP: {metrics['false_positives']}, FN: {metrics['false_negatives']}\\n\\n\")\n",
        "        \n",
        "        print(f\"üìÑ Reports saved to: {output_dir}\")\n",
        "    \n",
        "    def _create_visualizations(self, evaluation_results, output_dir):\n",
        "        \"\"\"Create evaluation visualizations\"\"\"\n",
        "        print(\"üìä Creating visualizations...\")\n",
        "        \n",
        "        # 1. Per-class performance comparison\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "        \n",
        "        class_names = [name for name in evaluation_results.keys() if name != 'overall']\n",
        "        precisions = [evaluation_results[name]['precision'] for name in class_names]\n",
        "        recalls = [evaluation_results[name]['recall'] for name in class_names]\n",
        "        f1_scores = [evaluation_results[name]['f1_score'] for name in class_names]\n",
        "        \n",
        "        # Precision\n",
        "        axes[0].bar(class_names, precisions, color='skyblue')\n",
        "        axes[0].set_title('Per-Class Precision')\n",
        "        axes[0].set_ylabel('Precision')\n",
        "        axes[0].tick_params(axis='x', rotation=45)\n",
        "        axes[0].set_ylim(0, 1)\n",
        "        \n",
        "        # Recall\n",
        "        axes[1].bar(class_names, recalls, color='lightcoral')\n",
        "        axes[1].set_title('Per-Class Recall')\n",
        "        axes[1].set_ylabel('Recall')\n",
        "        axes[1].tick_params(axis='x', rotation=45)\n",
        "        axes[1].set_ylim(0, 1)\n",
        "        \n",
        "        # F1-Score\n",
        "        axes[2].bar(class_names, f1_scores, color='lightgreen')\n",
        "        axes[2].set_title('Per-Class F1-Score')\n",
        "        axes[2].set_ylabel('F1-Score')\n",
        "        axes[2].tick_params(axis='x', rotation=45)\n",
        "        axes[2].set_ylim(0, 1)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_dir, \"per_class_performance.png\"), dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        # 2. Overall metrics pie chart\n",
        "        overall = evaluation_results['overall']\n",
        "        fig, ax = plt.subplots(figsize=(8, 8))\n",
        "        \n",
        "        labels = ['True Positives', 'False Positives', 'False Negatives']\n",
        "        sizes = [overall['true_positives'], overall['false_positives'], overall['false_negatives']]\n",
        "        colors = ['lightgreen', 'lightcoral', 'lightblue']\n",
        "        \n",
        "        ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
        "        ax.set_title('Overall Detection Results Distribution')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_dir, \"overall_distribution.png\"), dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        \n",
        "        print(f\"üìä Visualizations saved to: {output_dir}\")\n",
        "\n",
        "# Run evaluation if model exists\n",
        "if os.path.exists(\"best_model_path.txt\"):\n",
        "    with open(\"best_model_path.txt\", \"r\") as f:\n",
        "        model_path = f.read().strip()\n",
        "    \n",
        "    dataset_yaml_path = \"./yolo_dataset/dataset.yaml\"\n",
        "    \n",
        "    if os.path.exists(model_path) and os.path.exists(dataset_yaml_path):\n",
        "        print(\"üìä Running comprehensive model evaluation...\")\n",
        "        \n",
        "        evaluator = YOLOEvaluator(\n",
        "            model_path=model_path,\n",
        "            dataset_path=dataset_yaml_path,\n",
        "            conf_threshold=0.25,\n",
        "            iou_threshold=0.45\n",
        "        )\n",
        "        \n",
        "        evaluation_results = evaluator.evaluate_model(\"./evaluation_results\")\n",
        "        \n",
        "        if evaluation_results:\n",
        "            print(\"\\nüìä Evaluation Summary:\")\n",
        "            overall = evaluation_results['overall']\n",
        "            print(f\"   Overall Precision: {overall['precision']:.4f}\")\n",
        "            print(f\"   Overall Recall: {overall['recall']:.4f}\")\n",
        "            print(f\"   Overall F1-Score: {overall['f1_score']:.4f}\")\n",
        "            print(f\"   Total Detections: {overall['true_positives'] + overall['false_positives']}\")\n",
        "            print(f\"   Total Ground Truth: {overall['true_positives'] + overall['false_negatives']}\")\n",
        "    else:\n",
        "        print(\"‚ùå Model or dataset not found. Please ensure training completed successfully.\")\n",
        "else:\n",
        "    print(\"‚ùå No trained model found. Please run the training step first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Step 8: Summary and Next Steps\n",
        "\n",
        "Congratulations! You've successfully completed the entire YOLO training pipeline for biomedical object detection. Here's a summary of what we accomplished:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary of the complete pipeline\n",
        "print(\"üéâ YOLO Biomedical Object Detection - Training Complete!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nüìã What we accomplished:\")\n",
        "print(\"‚úÖ 1. Data Loading - Loaded CSV-annotated biomedical images\")\n",
        "print(\"‚úÖ 2. Data Visualization - Explored and visualized your dataset\")\n",
        "print(\"‚úÖ 3. Data Conversion - Converted CSV annotations to YOLO format\")\n",
        "print(\"‚úÖ 4. Dataset Creation - Created train/validation/test splits\")\n",
        "print(\"‚úÖ 5. Model Training - Trained YOLOv9 with biomedical-optimized settings\")\n",
        "print(\"‚úÖ 6. Model Inference - Tested predictions on validation data\")\n",
        "print(\"‚úÖ 7. Model Evaluation - Comprehensive performance analysis\")\n",
        "\n",
        "print(\"\\nüìÅ Generated files and directories:\")\n",
        "print(\"üìÇ yolo_dataset/ - YOLO format dataset\")\n",
        "print(\"üìÇ biomedical_yolo/ - Training results and model weights\")\n",
        "print(\"üìÇ inference_results/ - Inference results and annotated images\")\n",
        "print(\"üìÇ evaluation_results/ - Performance metrics and visualizations\")\n",
        "print(\"üìÑ best_model_path.txt - Path to your trained model\")\n",
        "\n",
        "print(\"\\nüîß Key features of this pipeline:\")\n",
        "print(\"‚Ä¢ Automatic CSV format detection and conversion\")\n",
        "print(\"‚Ä¢ Biomedical-optimized data augmentation\")\n",
        "print(\"‚Ä¢ Comprehensive evaluation metrics\")\n",
        "print(\"‚Ä¢ Visual result analysis\")\n",
        "print(\"‚Ä¢ Easy-to-use inference interface\")\n",
        "\n",
        "print(\"\\nüöÄ Next steps you can take:\")\n",
        "print(\"1. üîÑ Retrain with different parameters:\")\n",
        "print(\"   - Adjust epochs, batch size, or learning rate\")\n",
        "print(\"   - Try different YOLO model sizes (yolov9n, yolov9s, yolov9m, yolov9l, yolov9x)\")\n",
        "print(\"   - Experiment with different augmentation settings\")\n",
        "\n",
        "print(\"\\n2. üìä Improve model performance:\")\n",
        "print(\"   - Add more training data\")\n",
        "print(\"   - Balance your dataset classes\")\n",
        "print(\"   - Fine-tune hyperparameters\")\n",
        "print(\"   - Use data augmentation techniques\")\n",
        "\n",
        "print(\"\\n3. üîç Deploy your model:\")\n",
        "print(\"   - Use the trained model for inference on new images\")\n",
        "print(\"   - Integrate into your biomedical analysis pipeline\")\n",
        "print(\"   - Export to different formats (ONNX, TensorRT)\")\n",
        "\n",
        "print(\"\\n4. üìà Monitor and iterate:\")\n",
        "print(\"   - Track performance on new data\")\n",
        "print(\"   - Retrain with additional data\")\n",
        "print(\"   - Compare different model architectures\")\n",
        "\n",
        "print(\"\\nüí° Tips for better results:\")\n",
        "print(\"‚Ä¢ Ensure your CSV annotations are accurate\")\n",
        "print(\"‚Ä¢ Use high-quality, diverse training images\")\n",
        "print(\"‚Ä¢ Consider class imbalance in your dataset\")\n",
        "print(\"‚Ä¢ Monitor training metrics to avoid overfitting\")\n",
        "print(\"‚Ä¢ Validate on representative test data\")\n",
        "\n",
        "print(\"\\nüéØ Your trained model is ready for biomedical object detection!\")\n",
        "print(\"Use the inference functions to predict on new images.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
